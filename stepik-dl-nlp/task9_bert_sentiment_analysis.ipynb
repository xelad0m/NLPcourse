{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNKaJz5j_ylj"
   },
   "source": [
    "# Определение эмоциональной окраски твитов с помощью BERT\n",
    "\n",
    "При отсутствии более чем одной GPU, даже файнтюнинг BERT может занять существенное количество времени. Поэтому мы рассмотрим, наверное, самую простую задачу, на решение которой будем файнтюнить BERT: будем классифицировать предложения. \n",
    "- будем определять эмоциональную окраску твитов с помощью BERT\n",
    "  - возьмём предобученный BERT \n",
    "  - добавим к нему слой нейронов, чтобы обучить полученную модель для классификации предложений\n",
    "- не будем кодить руками обучение BERT, а покажем, как, максимально просто, максимально быстро, найти готовый предобученный BERT и, минимальным количеством кода, дофайнтюнить его для решения вашей задачи\n",
    "\n",
    "Авторы статьи про BERT советуют запускать всего от двух до четырёх эпох, чтобы получить хороший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "## Установка библиотек\n",
    "\n",
    "`pytorch-transformers`:\n",
    "- есть pytorch-интерфейс BERT, \n",
    "- есть удобные обёртки и для других популярных моделей (например, для XL трансформера, или GPT-2, или каких-то других моделей — например, для RoBERTa[1])\n",
    "- есть специальные модификации для конкретных задач. Например, для задачи классификации предложений (классификации текстов)\n",
    " \n",
    "На сегодняшний день, пожалуй, эта библиотека является самой популярной обёрткой для удобного использования BERT. \n",
    "\n",
    "[1] Liu Y. et al. Roberta: A robustly optimized bert pretraining approach //arXiv preprint arXiv:1907.11692. – 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "0NmMdkZO8R6q",
    "outputId": "1cc59bfa-1dbb-4540-cb22-196f399f62af"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-transformers\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow под CUDA 11, под 10.2 вобще нету (собирать из исходников), только 10.1, т.е. на моем GPU не пойдет\n",
    "- ставим скачанный под CPU pip install /mnt/EXT_STORAGE/Soft/CUDA/wheels/tensorflow_cpu-2.8.0-cp39-cp39-manylinux2010_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ok002ceNB8E7",
    "outputId": "06ef90d2-7518-4209-da66-1dd45c357c78"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences  # require tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oYsV4H8fCpZ-",
    "outputId": "b8812c8e-3149-475f-b4c0-262160485c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 760\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# сама модель BERT это 9.2 Гб тензоров, поэтому не на всяком GPU пойдет\n",
    "# device = 'cpu'\n",
    "if device == 'cpu':\n",
    "    print('cpu')\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Еще полезные штуки\n",
    "\n",
    "- Таблица параметров модели. Типа подробный `get_parameters()` \n",
    "- Все тензоры ноутбука\n",
    "- Очистить память от ненужных тензоров/моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.summary import count_parameters, dump_tensors, free_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "## Загрузка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы выбрали необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/).\n",
    "\n",
    "Датасет нам известен, уже посмотрели, на сегодня он не аллё по большому счету (на момент составления мож ищо туда-сюда):\n",
    "- охватывает короткий период зимы 2013-2014 года\n",
    "- авторазметка на основе смайликов неадекватна чуть более чем полностью (субъективно выборочно, тут могут быть другие мнения)\n",
    "  - как в топ позитивных биграм попадает `идиот целый`, например? Короче специфика лексики + специфика периода\n",
    "  - в чем была проблема хотя бы хеш-теги и урлы в отдельное поле вынести? Можно было б признак собрать +/- рабочий...\n",
    "- ценность тут не в разметке, а в том, что на ее основе была проанализирована морфологическая разметка (сочетания частей речи, характерные для положительных/отрицательных сообщений, и вот на ней уже можно что-то стоящее собрать, но исходные данные для этого хреновые, так что вот)\n",
    "\n",
    "**Очень любопытно, что жы покажет BERT**\n",
    "\n",
    "[1] Корпус коротких текстов Юлии Рубцовой: http://study.mokoron.com/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "pos_texts = pd.read_csv('datasets/bert_sentiment_analysis/positive.csv', encoding='utf8', sep=';', header=None)\n",
    "neg_texts = pd.read_csv('datasets/bert_sentiment_analysis/negative.csv', encoding='utf8', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62503</th>\n",
       "      <td>410304406702538752</td>\n",
       "      <td>1386659168</td>\n",
       "      <td>LediDu</td>\n",
       "      <td>@VadimKovalev я тоже в свое время по \"любви\" в...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11794</td>\n",
       "      <td>810</td>\n",
       "      <td>357</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18129</th>\n",
       "      <td>409377737779191809</td>\n",
       "      <td>1386438233</td>\n",
       "      <td>Ard_Rhena</td>\n",
       "      <td>@jester_zaffiro как быстро ты сдался, хехе..)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5440</td>\n",
       "      <td>93</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17241</th>\n",
       "      <td>409368929006813184</td>\n",
       "      <td>1386436133</td>\n",
       "      <td>nikadavdav</td>\n",
       "      <td>@DakotaMossIA @KatrynSLF @Marianna_Bis чья бы ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6195</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112353</th>\n",
       "      <td>411208490527768576</td>\n",
       "      <td>1386874718</td>\n",
       "      <td>sashulkaar</td>\n",
       "      <td>RT @AnyaSweet2603: аааа, прослезилась даже))))...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4120</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71300</th>\n",
       "      <td>410475422477197312</td>\n",
       "      <td>1386699941</td>\n",
       "      <td>Nesti_N</td>\n",
       "      <td>@MsKarlson ахах не не бойся) я аккуратно, я ж ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7140</td>\n",
       "      <td>227</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0           1           2   \\\n",
       "62503   410304406702538752  1386659168      LediDu   \n",
       "18129   409377737779191809  1386438233   Ard_Rhena   \n",
       "17241   409368929006813184  1386436133  nikadavdav   \n",
       "112353  411208490527768576  1386874718  sashulkaar   \n",
       "71300   410475422477197312  1386699941     Nesti_N   \n",
       "\n",
       "                                                       3   4   5   6   7   \\\n",
       "62503   @VadimKovalev я тоже в свое время по \"любви\" в...   1   0   0   0   \n",
       "18129   @jester_zaffiro как быстро ты сдался, хехе..)\\...   1   0   0   0   \n",
       "17241   @DakotaMossIA @KatrynSLF @Marianna_Bis чья бы ...   1   0   0   0   \n",
       "112353  RT @AnyaSweet2603: аааа, прослезилась даже))))...   1   0   2   0   \n",
       "71300   @MsKarlson ахах не не бойся) я аккуратно, я ж ...   1   0   0   0   \n",
       "\n",
       "           8    9    10  11  \n",
       "62503   11794  810  357   9  \n",
       "18129    5440   93   52   1  \n",
       "17241    6195   48   42   0  \n",
       "112353   4120   39   54   0  \n",
       "71300    7140  227  133   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_texts.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.200590021843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_texts[3].apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим токен начала текста `[CLS]` и разделитель `[SEP]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n",
    "\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Дим, ты помогаешь мне, я тебе, все взаимно, все правильно) [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренировочная и тестовая выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158783 68051\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gt), len(test_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "## Inputs\n",
    "\n",
    "Импортируем токенизатор для BERT (`pytorch_transformers.BertTokenizer`), который превратит наши тексты в набор токенов, соответствующих тем, что встречались в словаре предобученной модели:\n",
    "\n",
    "`bert_base_uncased` это модель, которая меньше, чем BERT Large, и содержит внутри 12 self-attention модулей\n",
    "- \"Uncased\" означает, что все слова в словаре этого токенайзера написаны в нижнем регистре\n",
    "\n",
    "*Заняло около минуты*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Z474sSC6oe7A",
    "outputId": "fbaa8fd8-bccd-4feb-ce52-beba5d293cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'ч', '##т', '##о', 'о', '##д', '##на', 'и', 'т', '##а', 'ж', '##е', 'к', '##о', '##с', '##м', '##е', '##т', '##и', '##ка', 'у', 'н', '##а', '##с', 'с', 'р', '##ы', '##ж', '##е', '##и', '.', 'м', '##ы', ',', 'н', '##а', '##в', '##е', '##р', '##н', '##о', '##е', ',', 'у', '##ж', 'о', '##ч', '##е', '##н', '##ь', 'д', '##о', '##л', '##г', '##о', 'з', '##на', '##к', '##о', '##м', '##ы', ')', ')', ')', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решетками обозначены так сказать \"суффиксы\" и \"окончания\", т.е. часто встречающиеся дополнения к другим токенам. Тут у BERT свой алгоритм токенизации (wordpieces). В данном случае он выдает почти посимвольное кодирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Что одна и та же косметика у нас с Рыжей. Мы ,наверное, уж очень долго знакомы))) [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87_kXUeT2-br"
   },
   "source": [
    "BERTу (в исполнении `pytorch_transformers`) нужно предоставить специальный формат входных данных.\n",
    "\n",
    "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
    "- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n",
    "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц. **Зачем это нужно?**\n",
    "  - BERT предобучается на двух задачах (предсказание маскированных слов в тексте, определение, является ли одно предложение продолжением другого предложения). Т.е. так в BERT подается информация о том, есть ли у нас два предложения в нашем входе, либо оно одно, нам нужен этот параметр segment_mask (почему он сам по `[SEP]` не поймет?).\n",
    "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Паддинг нужен для того, чтобы BERT мог работать с предложениями разной длины. Ну, например, в нашем случае, мы можем сказать, что максимальная длина предложения у нас будет равна 100, можно выбрать какую-то другую длину, это не сильно важно. И теперь более длинные предложения мы будем обрезать до 100 токенов, а для более коротких предложений использовать паддинг.\n",
    "- зачем тогда `[SEP]`?\n",
    "\n",
    "Чтобы добавить паддинг нашим предложениям, мы будем использовать готовую функцию из `keras` под названием `pad_sequences` (вот без керас/тензорфлоу паддинг не сделать никак...)\n",
    "- средняя длина сообщений 85 символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cp9BPRd1tMIo"
   },
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из тренировочной выборки выделяем **валидационную**:\n",
    "- на тренирочной выборке вычисляются **параметры** модели (веса, градиенты и т.п.)\n",
    "- на валидационной выборке подбираются **гиперпараметры** модели (количество слоев, дропауты и т.п.) - тут нам это не понадобится\n",
    "- на тестовой (если сценарий обучения включает валидационную выборку) оценивается уже тольк финальная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFbE-UHvsb7-"
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    input_ids, train_gt, \n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    attention_masks,\n",
    "    input_ids,\n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Данные - в тензоры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jw5K2A5Ko1RF"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки классов это **столбец** - тут не принципиально, а вообще так делается, если объекту нужно несколько меток классов присваивать (типа тегов, например)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем итераторы по данным с помощью `DataLoader` из торча, чтоб не грузить все данные в память.\n",
    "\n",
    "К тренировочному датасету прикручивается `RandomSampler` к валидационному достаточно подавать по очереди (`SequentialSampler`).\n",
    "\n",
    "Тут же задается объем батча (обучающего пакета)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEgLpFVlo1Z-"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    sampler=SequentialSampler(validation_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNl8khAhPYju"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):\n",
    "- это готовая модификация BERT для классификации\n",
    "- т.е. это обычный BERT с добавленным одним линейным слоем для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы помним, первый токен в каждом предложении в наших данных — это метка `[CLS]`. Скрытое состояние, относящееся к этой метке, должно содержать в себе агрегированное представление всего предложения (ибо она есть у всех предложений корпуса), которое дальше будет использоваться для классификации. \n",
    "\n",
    "Таким образом, когда мы скормили предложение в процессе обучения сети, выходом должен быть вектор со скрытым состоянием, относящийся к метке `[CLS]`. \n",
    "\n",
    "Дополнительный полносвязный слой, который мы добавили (руками `BertForSequenceClassification`), имеет размерность [\"hidden state\", \"количество классов\"] — это 2д тензор. И в нашем случае, количество классов равно \"2\", то есть, на выходе мы получим два числа, представляющих классы \"положительная эмоциональная окраска\", \"отрицательная эмоциональная окраска\". \n",
    "\n",
    "Сам процесс дообучения вычислительно достаточно дешёв. По факту, мы тренируем наш верхний слой и немного меняем веса во всех остальных слоях. Иногда некоторые слои специально замораживают или применяют разные стратегии работы с learning rate. В общем делают всё, чтобы сохранить хорошие веса в нижних слоях и ускорить процесс дообучения. \n",
    "\n",
    "В целом, замораживание слоёв BERT обычно не сильно сказывается на итоговом качестве, однако стоит помнить о тех случаях, когда домен для предобучения и дообучения был разным. Например, когда мы предобучили нашу сеть на каких-то официальных текстах (на правовых актах или на научных статьях), а дообучаем её на, например, твитах, на неформальной лексике. В таких случаях лучше тренировать все слои сети, не замораживая ничего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И кстаи, аналогичные модели есть и для других задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем модель:\n",
    "- `pytorch_transformers` бодро (за 1 мин.) выкачивает где-то 440 Мб упакованных параметров $BERT_{base}$\n",
    "- Созданный объект модели номинально занимает примерно **9.2 Гб** (включая наш последний слой на 2 X 768 = 1536 (+2 смещения) параметров)\n",
    "- Конечно, такая махина не в каждый GPU влезет, чтоб его целиком переобучать\n",
    "  - а по частям не получится, данные и модель должны быть на одном устройстве... как это имелось в виду запускать? \n",
    "  - имелся в виду гуглоколаб с Tesla P100 16 Gb\n",
    "\n",
    "Не лезет в GPU, штош:\n",
    "- зачем на 768 размер входа для твиторов по 80 символов (токенов и того меньше), но\n",
    "  - уменьшить размеры входов, эмбеддингов, число скрытых состояний энкодеров, словарь не получится, модель сохранена именно в таком виде, и не загрузится в другой конфигурации\n",
    "- зато можно уменьшить число самих энкодеров и голов механизма внимания\n",
    "  - в 760gtx 2 Gb влезло только по минимуму: 2 энкодера по 2 головы в каждом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = BertConfig(num_labels=2,\n",
    "                            vocab_size=30522,\n",
    "                            hidden_size=768,    \n",
    "                            num_hidden_layers=2,#12,\n",
    "                            num_attention_heads=2,#12,\n",
    "                            intermediate_size=3072,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gFsCTp_mporB",
    "outputId": "dd067229-1925-4b37-f517-0c14e25420d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+-----+-------------+------------+---------------+------------+\n",
      "|                    Modules/Tensors                     | GPU |    Shape    | Parameters |      Type     |   Memory   |\n",
      "+--------------------------------------------------------+-----+-------------+------------+---------------+------------+\n",
      "|         bert.embeddings.word_embeddings.weight         |  +  | 30522 x 768 |  23440896  | torch.float32 | 2062798848 |\n",
      "|       bert.embeddings.position_embeddings.weight       |  +  |  512 x 768  |   393216   | torch.float32 |  34603008  |\n",
      "|      bert.embeddings.token_type_embeddings.weight      |  +  |   2 x 768   |    1536    | torch.float32 |   135168   |\n",
      "|            bert.embeddings.LayerNorm.weight            |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|             bert.embeddings.LayerNorm.bias             |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|    bert.encoder.layer.0.attention.self.query.weight    |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|     bert.encoder.layer.0.attention.self.query.bias     |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|     bert.encoder.layer.0.attention.self.key.weight     |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|      bert.encoder.layer.0.attention.self.key.bias      |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|    bert.encoder.layer.0.attention.self.value.weight    |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|     bert.encoder.layer.0.attention.self.value.bias     |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|   bert.encoder.layer.0.attention.output.dense.weight   |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|    bert.encoder.layer.0.attention.output.dense.bias    |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "| bert.encoder.layer.0.attention.output.LayerNorm.weight |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|  bert.encoder.layer.0.attention.output.LayerNorm.bias  |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|     bert.encoder.layer.0.intermediate.dense.weight     |  +  |  3072 x 768 |  2359296   | torch.float32 | 207618048  |\n",
      "|      bert.encoder.layer.0.intermediate.dense.bias      |  +  |     3072    |    3072    | torch.float32 |   270336   |\n",
      "|        bert.encoder.layer.0.output.dense.weight        |  +  |  768 x 3072 |  2359296   | torch.float32 | 207618048  |\n",
      "|         bert.encoder.layer.0.output.dense.bias         |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|      bert.encoder.layer.0.output.LayerNorm.weight      |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|       bert.encoder.layer.0.output.LayerNorm.bias       |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|    bert.encoder.layer.1.attention.self.query.weight    |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|     bert.encoder.layer.1.attention.self.query.bias     |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|     bert.encoder.layer.1.attention.self.key.weight     |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|      bert.encoder.layer.1.attention.self.key.bias      |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|    bert.encoder.layer.1.attention.self.value.weight    |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|     bert.encoder.layer.1.attention.self.value.bias     |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|   bert.encoder.layer.1.attention.output.dense.weight   |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|    bert.encoder.layer.1.attention.output.dense.bias    |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "| bert.encoder.layer.1.attention.output.LayerNorm.weight |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|  bert.encoder.layer.1.attention.output.LayerNorm.bias  |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|     bert.encoder.layer.1.intermediate.dense.weight     |  +  |  3072 x 768 |  2359296   | torch.float32 | 207618048  |\n",
      "|      bert.encoder.layer.1.intermediate.dense.bias      |  +  |     3072    |    3072    | torch.float32 |   270336   |\n",
      "|        bert.encoder.layer.1.output.dense.weight        |  +  |  768 x 3072 |  2359296   | torch.float32 | 207618048  |\n",
      "|         bert.encoder.layer.1.output.dense.bias         |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|      bert.encoder.layer.1.output.LayerNorm.weight      |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|       bert.encoder.layer.1.output.LayerNorm.bias       |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|                bert.pooler.dense.weight                |  +  |  768 x 768  |   589824   | torch.float32 |  51904512  |\n",
      "|                 bert.pooler.dense.bias                 |  +  |     768     |    768     | torch.float32 |   67584    |\n",
      "|                   classifier.weight                    |  +  |   2 x 768   |    1536    | torch.float32 |   135168   |\n",
      "|                    classifier.bias                     |  +  |      2      |     2      | torch.float32 |    176     |\n",
      "+--------------------------------------------------------+-----+-------------+------------+---------------+------------+\n",
      "Total Trainable Params: 38605058\n",
      "Total memory: 3239.87 Mb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38605058"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=configuration)\n",
    "model.to(device)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы статьи про BERT советуют выбирать: \n",
    "- learning rate из следующего списка: $5 \\cdot 10^{-5}, 3 \\cdot 10^{-5}, 2 \\cdot 10^{-5}$, \n",
    "- количество эпох дообучения: 2, 3, 4.\n",
    "- размер батча: 16, 32\n",
    "\n",
    "### Создаем параметры обучения \n",
    "В виде json подобной структуры, где:\n",
    "- `no_decay` паттерны имен параметров, по которым не пересчитывать градиенты\n",
    "\n",
    "### Оптимизатор с \"регуляризацией\"\n",
    "\n",
    "`AdamW` - это реализация `Adam` с применением **Weight Decay**. \n",
    "\n",
    "Что такое Weight Decay? При каждом обновлении веса давайте кроме движения в сторону антиградиента еще и будем вычитать маленький кусочек веса, умноженный на некоторый гиперпараметр. Например, формула стохастического градиентного спуска с применением Weight Decay будет выглядеть так:\n",
    "\n",
    "$w = w - lr * \\dfrac{\\partial L}{\\partial w} - lr * wd * w$ \n",
    "\n",
    "Здесь lr - learning rate, wd - weight decay, гиперпараметр.\n",
    "\n",
    "Если Вы внимательно посмотрите на эту формулу, то заметите, что в случае стохастического градиентного спуска Weight Decay эквивалентен применению L2-регуляризации к loss-функции:\n",
    "\n",
    "$$L_{new} = L + \\dfrac{wd}{2} ||w||^2 \\\\\n",
    " \n",
    "\\dfrac{\\partial (L_{new})}{\\partial w} = \\dfrac{\\partial L}{\\partial w} + wd \\cdot w \\\\\n",
    "\n",
    "w = w - lr \\cdot \\dfrac{\\partial L_{new}}{\\partial w} = w - lr * \\dfrac{\\partial L}{\\partial w} - lr * wd * w $$\n",
    "\n",
    "Однако, L2-регуляризация (**меняем loss-функцию**) и Weight Decay (**не меняем loss-функцию**, меняем только способ обновления весов) работают одинаково только в простом случае стохастического градиентного спуска, в случае адаптивных оптимизаторов, например, Адама, эти два подхода различаются (причем эмпирически было показано, что часто Weight Decay работает лучше). Вся эта история породила некоторую путаницу в терминилогии, и во многих библиотеках Адам реализовали именно с применением L2-регуляризации, ошибочно называя такой подход Weight Decay.  Авторы статьи [Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101) решили разграничить Adam+L2 и Adam+Weight Decay, назвав последнее AdamW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxSMw0FrptiL"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл обучения\n",
    "\n",
    "На самом деле это 1 итерация цикла (1 эпоха), если надо, можно еще раз тыкнуть ичейку.\n",
    "\n",
    "- переводим модель в train mode, \n",
    "- распаковываем входные данные (вектор с индексами токенов и метки классов)\n",
    "- помещаем наши данные на GPU с помощью \n",
    "- не забываем очистить градиенты с прошлого шага с помощью `zero_grad()` \n",
    "- делаем forward pass, считаем loss, затем делаем backward pass, считаем градиенты, \n",
    "- дальше — стандартно — делаем optimizer.step(). \n",
    " \n",
    "Кроме того, в процессе обучения мы будем рисовать график и считать лосс. В конце каждой эпохи (в нашем случае — в конце единственной эпохи) посчитаем лосс на нашей обучающей выборке.\n",
    "\n",
    "- На GPU у авторов семинара: ~15 мин./ эпоха\n",
    "- На GPU на старой видеокарте: ~40 мин./ эпоха (на урезанной с 12х12 до 2 энкодеров по 2 головы модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "6J-FYdx6nFE_",
    "outputId": "8e388ad1-f9db-4c7b-d080-6c0a0e964610"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss на обучающей выборке: 0.05143\n",
      "Процент правильных предсказаний на валидационной выборке: 97.73%\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "# Обучение\n",
    "# Переводим модель в training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss[0].backward()\n",
    "    \n",
    "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем loss\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "    # Рисуем график\n",
    "    clear_output(True)\n",
    "    plt.plot(train_loss_set)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
    "\n",
    "\n",
    "# Валидация\n",
    "# Переводим модель в evaluation mode\n",
    "model.eval()\n",
    "\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in validation_dataloader:   \n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)     \n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)\n",
    "\n",
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на валидационной выборке: 97.73%\n"
     ]
    }
   ],
   "source": [
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# Оценка качества на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAN0LZBOOPVh"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(test_gt)\n",
    "\n",
    "prediction_data = TensorDataset(\n",
    "    prediction_inputs,\n",
    "    prediction_masks,\n",
    "    prediction_labels\n",
    ")\n",
    "\n",
    "prediction_dataloader = DataLoader(\n",
    "    prediction_data, \n",
    "    sampler=SequentialSampler(prediction_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На GPU на старой видеокарте: ~5 мин. (на урезанной с 12х12 до 2 энкодеров по 2 головы модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hba10sXR7Xi6"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Сохраняем предсказанные классы и ground truth\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)  \n",
    "    test_preds.extend(batch_preds)\n",
    "    test_labels.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на отложенной выборке составил: 97.67%\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(test_labels, test_preds)\n",
    "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
    "    acc_score*100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильных предсказаний: 1586/68051\n"
     ]
    }
   ],
   "source": [
    "print('Неправильных предсказаний: {0}/{1}'.format(\n",
    "    sum([z[0] != z[1] for z in zip(test_labels,  test_preds)]),\n",
    "    len(test_labels)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы показали, что предобученный BERT может быстро (всего за одну эпоху) давать хорошее качество при решении задачи анализа эмоциональной окраски текстов. Кроме того, обратите внимание, что мы не тюнили параметры и использовали сравнительно маленький размеченный корпус, чтобы получить accuracy больше 98%. Тем не менее, если не делать дообучение под конкретную задачу вовсе, то получить хорошее качество вряд ли выйдет.\n",
    "\n",
    "- как языковая модель BERT очень хорош, т.е.\n",
    "  - сама классификая - по языковой модели выбор меток как в обучающей выборке - решается на ура\n",
    "  - это не отменяет того, что сама обучающая выборка слабая\n",
    "- для такой задачи совершенно не нужны все 12 слоев модели BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет с отзывами на фильмы. Например, используйте датасет [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dataset = pd.read_csv('./datasets/bert_sentiment_analysis/homework/IMDB_Dataset.csv')\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте для дообучения BERT датасет IMDB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на вопросы:\n",
    "1. удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n",
    "2. удалось ли получить хорошее качество классификации всего за одну эпоху?\n",
    "3. подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n",
    "    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n",
    "    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**на BERT мы этого делать не будем**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заморозка слоев модели\n",
    "\n",
    "Иногда используется в сценариях трансферлернинга, дообучения и т.п., чтобы не тратить время на пересчет backbone модели.\n",
    "\n",
    "В общем в PyTorch есть несколько способов заморозить слои (по сути, защитить их от изменения оптимизатором).\n",
    "\n",
    "Допустим у нас есть следующая модель:\n",
    "\n",
    "    class OurModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.pretrained_model = load_super_pretrained_model()\n",
    "            self.output_layer = nn.Linear(...)\n",
    " \n",
    "\n",
    "**Способ 1 (предпочтительный).** Не передавать в оптимизатор те параметры, которые надо заморозить\n",
    "\n",
    "Обычно мы создаём оптимизатор для такой модели как\n",
    "\n",
    "    model = OurModel()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "Если мы не хотим учить часть нашей модели (например, предобученные слои self.pretrained_model), тогда можно сделать так:\n",
    "\n",
    "    model = OurModel()\n",
    "    optimizer = torch.optim.Adam(model.output_layer.parameters(), lr=1e-3)\n",
    "\n",
    "Это подход \"по умолчанию\".\n",
    "\n",
    "**Способ 2.** Грязный хак: спрятать параметры от самой модели\n",
    "\n",
    "Когда мы вызываем model.parameters(), модель делает проход по своим полям и либо собирает экземпляры класса nn.Parameter, либо рекурсивно вызывает .parameters()  (если поле имеет тип nn.Module). Если модель видит поле какого-то другого типа, она его игнорирует.\n",
    "\n",
    "Поэтому можно обернуть вложенную модель, которую не надо учить, например, в список.\n",
    "\n",
    "    class OurModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.pretrained_model = [load_super_pretrained_model()]\n",
    "            self.output_layer = nn.Linear(...)\n",
    "\n",
    "В этом случае в оптимизатор не попадут параметры self.pretrained_model\n",
    "\n",
    "    model = OurModel()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "Этим можно пользоваться осторожно, но надо помнить, что в разработке явное лучше, чем скрытое.\n",
    "\n",
    "**Способ 3.** Гибкий вариант: занулять градиенты параметров руками\n",
    "\n",
    "После того, как мы вызвали loss.backward(), у всех объектов-экземпляров класса nn.Parameter появится атрибут .grad, это тензор, имеющий ту же форму, что и сам тензор параметров, и содержащий значения производной функции потерь по этой переменной.\n",
    "\n",
    "Тогда можно руками пройтись по нужным параметрам и занулить у них grad. При этом надо именно обнулить значения тензора, а не перезаписать его нулём (обратите внимание на квадратные скобки):\n",
    "\n",
    "    loss.backward()\n",
    "    for param in model.pretrained_model.parameters():\n",
    "        param.grad[:] = 0  # или param.grad.zero_()\n",
    "        \n",
    "Такой вариант наиболее удобен, когда надо на разных шагах оптимизации нужно оптимизировать разные переменные. Это достаточно экзотическая ситуация и в рамках этого курса это не пригодится, лучше пользоваться первым способом."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Fine-Tuning Sentence Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
