{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе туториала `transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- из данных убраны дубли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = f\"./datasets/train_clean.csv\"\n",
    "SMALL_CSV = f\"./cache/train.csv\"\n",
    "SCORING_CSV = f\"./datasets/test.csv\"\n",
    "\n",
    "USE_SMALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасеты\n",
    "\n",
    "- пакет huggingface datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_dataset = datasets.Dataset.from_csv(SMALL_CSV if USE_SMALL else TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 if USE_SMALL else 0.02\n",
    "arxiv_dataset = arxiv_dataset.train_test_split(test_size=test_size)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arxiv_dataset[\"train\"]), len(arxiv_dataset[\"test\"]), arxiv_dataset[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_dataset = datasets.Dataset.from_csv(SCORING_CSV)\n",
    "len(scoring_dataset), scoring_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")   # 1.3 MB\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")   # 1.3 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Почти все последовательности без обрезки: max = 1096 / 103\n",
    "        - max_length=1024\n",
    "        - max_length=128\n",
    "    \"\"\"\n",
    "    srcs = [prefix + doc for doc in examples[\"abstract\"]]\n",
    "    model_inputs = tokenizer(srcs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        trgs = tokenizer(examples[\"title\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = trgs[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_arxiv = arxiv_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_arxiv[\"train\"][0].keys(), tokenized_arxiv[\"train\"][0][\"abstract\"], tokenized_arxiv[\"train\"][0][\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./T5-base-results\",#\"./T5-small-results\",\n",
    "    optim=\"adamw_torch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_arxiv[\"train\"],\n",
    "    eval_dataset=tokenized_arxiv[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 эпохи: 2,5 часа (RTX2060 6GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(example):\n",
    "    input_ids = tokenizer(prefix + example[\"abstract\"], \n",
    "                        max_length=1024, \n",
    "                        truncation=True, \n",
    "                        return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "    outputs = model.generate(input_ids.to(device))\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "arxiv_dataset[\"test\"][n][\"abstract\"], arxiv_dataset[\"test\"][n][\"title\"], generate(arxiv_dataset[\"test\"][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 42\n",
    "arxiv_dataset[\"test\"][n][\"abstract\"], arxiv_dataset[\"test\"][n][\"title\"], generate(arxiv_dataset[\"test\"][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU-score\n",
    "\n",
    "T5-small\n",
    "- BLEU-score: **0.16563** (3 эпохи)\n",
    "\n",
    "Самоделки:\n",
    "- 0.02457 (словарь 6152, по 5 эпох по 5r-4, 1e-3, min.val.loss = 3.875) \n",
    "- **0.19204** (словарь 60 тыс. ~15 эпох с шагом 5e-4 -> 5e-5, min.val.loss = 2.289)\n",
    "- 0.12601 (словарь 84 тыс. много разных эпох, сходится плохо, min.val.loss = 3.305)\n",
    "- 0.10644 (BPE, словарь 16 тыс., много разных эпох, сходится плохо, min.val.loss = 3.8)\n",
    "\n",
    "T5-base\n",
    "- BLEU-score: 0.07422 (без обучения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "references = []\n",
    "candidates = []\n",
    "for example in tqdm(tokenized_arxiv[\"test\"]):\n",
    "    references.append([example[\"title\"].split()])\n",
    "    candidates.append(generate(example).split())\n",
    "\n",
    "score = bleu_score(candidates, references, max_n=3, weights=[1/3]*3)\n",
    "\n",
    "print('BLEU-score: {0:.5f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NAME = \"T5\" if USE_SMALL else \"T5-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация заголовков для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "abstracts = []\n",
    "titles = []\n",
    "\n",
    "for example in tqdm(scoring_dataset):\n",
    "    abstracts.append(example[\"abstract\"])\n",
    "    titles.append(generate(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, например"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts[1], titles[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем полученные заголовки в файл формата `<abstract>,<title>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\n",
    "submission_df.to_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"title\"].apply(lambda x: len(str(x).split())).describe()[[\"mean\",\"std\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью скрипта `generate_csv` приводим файл `submission_prediction.csv` в формат, необходимый для отправки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.create_submission import generate_csv\n",
    "\n",
    "generate_csv(input_file=f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\", \n",
    "             output_file=f'./submission/submission_{SUBMISSION_NAME}.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с примером (Score: 0.097), прост чтоб увидеть, что чето похожее посчиталось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(f'./datasets/sample_submission.csv')\n",
    "df = pd.read_csv(f'./submission/submission_{SUBMISSION_NAME}.csv')\n",
    "\n",
    "df[\"Predict\"].mean(), sample_df[\"Predict\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С учетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"./datasets/train.csv\")\n",
    "submission_df = pd.read_csv(\"./submission/predicted_titles_T5tune.csv\")\n",
    "\n",
    "intersect_idx = np.intersect1d(submission_df[\"abstract\"].str.lower(), train_df[\"abstract\"].str.lower(), return_indices=True)\n",
    "\n",
    "submission_df.loc[intersect_idx[1], 'title'] = train_df.loc[intersect_idx[2], 'title'].values\n",
    "\n",
    "submission_df.to_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}_fake.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.create_submission import generate_csv\n",
    "\n",
    "generate_csv(input_file=f\"./submission/predicted_titles_{SUBMISSION_NAME}_fake.csv\", \n",
    "             output_file=f'./submission/submission_{SUBMISSION_NAME}_fake.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5-small:\n",
    "- **Score: 0.26174** w/o tuning\n",
    "- **Score: 0.34497** tuning\n",
    "- **Score: 0.51810** + добавление правильных меток из трейна\n",
    "\n",
    "T5-base:\n",
    "- **Score: 0.20510** w/o tuning\n",
    "- для обучения с имеющейся длиной последовательности не хватает памяти GPU"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d00ba0b92f737b23b3e678e3a3ceb3fe4e948ad1ab95d9c6fdcbb4b4ec65f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
