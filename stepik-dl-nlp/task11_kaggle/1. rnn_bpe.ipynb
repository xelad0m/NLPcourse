{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем генерацию последовательностей на RNN\n",
    "- это задача суммаизации, обычно решается seq2seq методами\n",
    "- интересно, что даст просто RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload    \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "from transformers.utils import logging\n",
    "from helpers.utils import count_parameters, epoch_time\n",
    "\n",
    "import youtokentome as yttm\n",
    "\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.deterministic = True   # avoid some rnn issues on some cuDNN versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'models/lstm_bpe_baseline.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасеты\n",
    "\n",
    "- жаль, что yttm не умеет сериализоваться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUICK_RUN = False\n",
    "\n",
    "DICT_SIZE = 300 if QUICK_RUN else 3000\n",
    "\n",
    "TRAIN_FILE = f\"{'./cache/' if QUICK_RUN else './datasets/'}train.csv\"\n",
    "FIN_TEST_FILE = f\"{'./cache/' if QUICK_RUN else './datasets/'}test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('<eoa>', ['hello world!', 'gnu is not unix :((( #sometag'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BPEncoder():\n",
    "    def __init__(self, path_to_data, dict_size=1000):\n",
    "        \"\"\"YouTokenToMe - работает только через внешний файл\"\"\"\n",
    "        \n",
    "        self.eoa = \"<eoa>\"\n",
    "        self.train_file = \"./cache/input_file.txt\"\n",
    "        self.model_file = MODEL_NAME + \".yttm\"\n",
    "        self.dict_size = dict_size\n",
    "\n",
    "        print(\"Reading data...\")\n",
    "        self.train_data = pd.read_csv(path_to_data)\n",
    "        with open(\"./cache/input_file.txt\", 'w') as f:\n",
    "            f.writelines((self.train_data[\"abstract\"] + self.eoa + self.train_data[\"title\"] + \"\\n\").to_list())\n",
    "\n",
    "        if not os.path.isfile(self.model_file):\n",
    "            print(\"Train tokenizer...\")\n",
    "            yttm.BPE.train(data=self.train_file, vocab_size=self.dict_size, model=self.model_file)\n",
    "\n",
    "        self.tokenizer = yttm.BPE(self.model_file)\n",
    "    \n",
    "    def encode(self, texts):\n",
    "        texts = [t.lower() for t in texts]\n",
    "        encodings = self.tokenizer.encode(texts, output_type=yttm.OutputType.ID, bos=2, eos=3)\n",
    "        length = list(map(len, encodings))\n",
    "        return {\"input_ids\": encodings, \"length\": length}\n",
    "    \n",
    "    def tokenize(self, texts):\n",
    "        return self.tokenizer.encode(texts, output_type=yttm.OutputType.SUBWORD, bos=2, eos=3)\n",
    "\n",
    "    def padded_encode(self, texts, dtype='int32', batch_first = True):\n",
    "        vectors = self.tokenizer.encode(texts, output_type=yttm.OutputType.ID, bos=2, eos=3)\n",
    "\n",
    "        max_batch_len = max(map(len, vectors))\n",
    "        data_ix = np.zeros([len(texts), max_batch_len], dtype)\n",
    "        \n",
    "        for i in range(len(texts)):\n",
    "            data_ix[i, :len(vectors[i])] = vectors[i]\n",
    "        \n",
    "        if not batch_first:                                     # [batch, token] -> [token, batch] (не используется)\n",
    "            data_ix = np.transpose(data_ix)\n",
    "\n",
    "        return {\"input_ids\": data_ix}\n",
    "\n",
    "    def decode(self, vectors, drop_special_tokens=True):\n",
    "        return self.tokenizer.decode(vectors, \n",
    "                                     ignore_ids=[0,1,2,3] if drop_special_tokens else None)\n",
    "\n",
    "bpe = BPEncoder(TRAIN_FILE, dict_size=DICT_SIZE)\n",
    "bpe.tokenizer.id_to_subword(bpe.tokenizer.subword_to_id(bpe.eoa)), \\\n",
    "bpe.decode(bpe.encode([\"Hello world!\", \"GNU is not Unix :((( #sometag\"])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArXivBPE(Dataset):\n",
    "    def __init__(self, path, tokenizer, drop_long=True):\n",
    "        \"\"\"Добавлен спец.токен для разделения аннотации и заголовка, \n",
    "        чтоб НС запоминала такие места:\n",
    "        - предполагается, что также он будет добавлен к стартовой последовательности \n",
    "        при генерации\n",
    "        - весь датасет кодируется без паддинга, чтоб добавить паддинг уже в батчи\n",
    "        - не включаем длинные последовательности (больше 1200 символов, 75% квантиль)\"\"\"\n",
    "\n",
    "        print(\"Reading data...\")\n",
    "        self.data = pd.read_csv(path)\n",
    "        self.data.drop_duplicates(inplace=True, ignore_index=True)\n",
    "        if drop_long:\n",
    "            self.data = self.data[self.data.applymap(lambda x: len(str(x))).abstract < 1200].reset_index(drop=True)\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.sequences = self.data[\"abstract\"] + self.tokenizer.eoa + self.data[\"title\"]\n",
    "\n",
    "        print(\"Encoding data...\")\n",
    "        self.encodings = self.tokenizer.encode(self.sequences.tolist())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"sequence\"] = self.sequences[idx]\n",
    "        item[\"length\"] = self.encodings[\"length\"][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def split(self, split=0.7, split_ratio=None):\n",
    "        \"\"\" Выделение тестовой/валидационной выборки\n",
    "        - принимает либо долю тренировочной выборки, либо список долей любой длины\n",
    "        - все делать руками, это и есть новый подход torchtext вместо legacy Dataset?\"\"\"\n",
    "        size = len(self)\n",
    "        split_ratio = split_ratio if split_ratio else [split, 1 - split]\n",
    "        split_size = [int(r * size) for r in split_ratio]\n",
    "        split_size[-1] = size - sum(split_size[:-1])\n",
    "        return torch.utils.data.random_split(self, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Encoding data...\n"
     ]
    }
   ],
   "source": [
    "all_train_dataset = ArXivBPE(TRAIN_FILE, tokenizer=bpe)  # Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- тренировочный, валидационный и тестовый датасеты (`Subset`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76783, 783, 785]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = all_train_dataset.split(split_ratio=[0.98, 0.01, 0.01])  # Subset\n",
    "\n",
    "list(map(len, (train_dataset, val_dataset, test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данные для итогового скоринга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_test_src = pd.read_csv(FIN_TEST_FILE).abstract.to_list()    # итоговые тестовые резюме статей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- что получается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 81, 4, 46, 142, 251, 476, 46, 2254, 2446, 129, 75, 2301, 475, 133, 755, 502, 93, 75, 514, 93, 623, 296, 25, 750, 431, 149, 81, 235, 7, 454, 151, 465, 368, 153, 849, 183, 559, 97, 81, 623, 93, 81, 735, 262, 735, 766, 129, 75, 2301, 1483, 649, 235, 7, 454, 151, 465, 296, 25, 750, 184, 1380, 129, 819, 650, 362, 881, 262, 2135, 923, 2700, 732, 1996, 372, 296, 25, 750, 428, 1921, 117, 649, 1388, 164, 1957, 235, 7, 454, 151, 465, 2446, 162, 2412, 240, 1249, 887, 849, 445, 163, 2697, 183, 93, 1065, 129, 881, 262, 2135, 2446, 202, 240, 1249, 2805, 184, 1927, 129, 1628, 483, 4, 46, 1810, 1675, 46, 1242, 162, 240, 1249, 2805, 184, 732, 2134, 129, 400, 93, 81, 296, 25, 750, 1852, 224, 138, 7, 454, 151, 465, 296, 25, 750, 129, 75, 2301, 475, 1020, 107, 285, 371, 1378, 111, 2135, 3], 'length': 158, 'sequence': \"the 'standard' confidence interval for a poisson parameter is only one of a number of estimation intervals based on the chi-square distribution that may be used in the estimation of the mean or mean rate for a poisson model. other chi-square intervals are available for experimenters using bayesian or structural inference methods. exploring these intervals also leads to other alternate approximate chi-square intervals. although coverage probability may not always be of interest for bayesian or structural intervals, coverage probabilities are useful for validating 'objective' priors. coverage probabilities are explored for all of the intervals considered.<eoa>chi-square intervals for a poisson parameter - bayes, classical and   structural\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"the 'standard' confidence interval for a poisson parameter is only one of a number of estimation intervals based on the chi-square distribution that may be used in the estimation of the mean or mean rate for a poisson model. other chi-square intervals are available for experimenters using bayesian or structural inference methods. exploring these intervals also leads to other alternate approximate chi-square intervals. although coverage probability may not always be of interest for bayesian or structural intervals, coverage probabilities are useful for validating 'objective' priors. coverage probabilities are explored for all of the intervals considered.<eoa>chi-square intervals for a poisson parameter - bayes, classical and structural\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "bpe.decode(train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итераторы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "   \"\"\"Дополняем батч паддингом до размера максимального в батче, чтобы не гонять \n",
    "   максимальный по корпусу паддинг:\n",
    "   - все делать руками, это и есть новый подход torchtext вместо legacy Field ?\"\"\" \n",
    "   \n",
    "   res = {}\n",
    "   for key in batch[0].keys():\n",
    "      if key == 'length':\n",
    "         tuple_of_seqs = tuple(map(lambda x: x[key], batch))\n",
    "         res[key] = torch.LongTensor(tuple_of_seqs)\n",
    "      elif key != \"sequence\":\n",
    "         tuple_of_seqs = tuple(map(lambda x: torch.LongTensor(x[key]), batch))\n",
    "         res[key] = torch.nn.utils.rnn.pad_sequence(tuple_of_seqs, padding_value=0, \n",
    "                                                                  batch_first=True)\n",
    "\n",
    "   return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(dataset, batch_size, shuffle=True, **kwargs):\n",
    "    return DataLoader(dataset, \n",
    "                      batch_size=batch_size, \n",
    "                      shuffle=shuffle, \n",
    "                      collate_fn=collate_batch, \n",
    "                      **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,   81,  501, 1973,   99,  922,  892,   80, 1335,   75, 1985,   77,\n",
       "            27, 2074,   99,  111,  461,  801,  846, 2359,  200,   82,   90,   76,\n",
       "           167,   90,  205,  104,   27,  562,   76,  328,   35,  558,    5, 1844,\n",
       "          2226, 1529,  184, 2178, 2353,  159,   75, 2173,  217,   93, 2205,  110,\n",
       "            93, 1511, 1674,  254, 2450, 2122,  140,  214,  237, 2917,  142,  352,\n",
       "           255,  392, 2435,  758,   81, 2226, 2424,  171,   26, 1624, 2122,  140,\n",
       "           214,  110, 1978,  136,  233,  117,   75, 2649, 1010, 1962, 1768, 1195,\n",
       "            26,   97,  898, 1973,  202,   81, 2122,  140,  214,  237, 2917,  142,\n",
       "           352,  255,  392, 2435,  482,  643,   81, 2100,  517,  129,   81,  328,\n",
       "            35,  558,    5, 2226,  117,  183,  787, 1253,  715,  728,  456,  643,\n",
       "           152,  134,  668,  162,   81, 1423, 1862,  922, 1136,  139,  117, 2702,\n",
       "            17,  111, 1097,  185, 2916, 2740,   93,   81, 1985,   77,   26,  243,\n",
       "           133, 1171,  153,   81, 1844, 2226, 1529,  129,   81,  128,  337,  143,\n",
       "           298,  174,  187,   15,   23,   16, 2613,   85,  356,  181, 1503,   15,\n",
       "            33, 2672,  219,   93,   88,   23,  266,   25,  164,  117,  128,  283,\n",
       "           164,  264,  183, 2914,  123,  237,  200, 2122,  140,  214,  110,   93,\n",
       "          2917,  142,  352,  255,  187, 2640, 1036,   93,   82,  124,    7,  171,\n",
       "           235,   13,   90,  971,   27,   82,  124,    7,  171,  107,  236,  971,\n",
       "            27,  973,  688,  171,  235,   13,   90,  971,  111,  230,   92,  121,\n",
       "           434,  342, 1751,  178,   26, 1194, 1231, 2914,  430,   93,   81,  128,\n",
       "            16,   15, 2672,  219,   93,  128,  283,  164,  117,   88,   23,  266,\n",
       "            25,  164,  133, 2610,  129, 2122,  140,  214,  237,   82,  124,    7,\n",
       "           171,  235,   13,   90,  174,  714,  728, 2163,   11,  117,  183,  413,\n",
       "          2411, 2891, 1647,   93,   81, 2122,  140,  214,  237,  392, 2435,  649,\n",
       "           628, 2917,  142,  352,  255,  706, 1945,  188,  430,   93,  328,   35,\n",
       "           558,    5, 2226, 1529,  200, 2917,  142,  352,  255, 2100,  517, 2122,\n",
       "           140,  214,  110,   47, 1561,  149,  796,  592,   93, 2122,  140,  214,\n",
       "           237, 2100,  272,    3],\n",
       "         [   2,   81, 1170,  902,  111,  899,   12,  158,   93,    4,  677,  790,\n",
       "          1835,  970, 2682,  129,  447,  182,  108,  821,  102, 1996,  111,  490,\n",
       "            27,  261, 1672,  620,  157,  447,  182,  108, 2352,    5,  111,  354,\n",
       "          1022,   26,  131, 1688,   81,  429,   93,  864,  588, 2136, 1544,  821,\n",
       "           102, 1996,   93, 2620,  790,  393, 2842,  134, 2162,  162,  131,  692,\n",
       "            75,  824, 1220,  781,  562,  447,  182,  108, 1991,  184,  100, 1361,\n",
       "           200, 2477,  106,   81, 1260,  181,  337,  981,  354, 2158, 1415,  111,\n",
       "          2315, 1797,   93,  447,  182,  108, 1544,  162, 2596,   27,  797,   81,\n",
       "           354, 1161,  764,   27,   81,  706,  454, 2180,  753,  387,   93,  354,\n",
       "          1544,   11,  111, 1272, 2199,  277,  739,  821,  102, 1996,  137, 1057,\n",
       "           131,  221,    5,   29,  105,  864, 2881,  113, 1272, 1829,  153, 2000,\n",
       "            11,   81, 1908,  447,  182,  108, 2352,    5,  623,  129,  400, 1544,\n",
       "            11,   93,   81,  354,   26,   81,  864, 1272,  868,  133,   81,  761,\n",
       "            93,   75,  892,  358,  807,  387,  429,   60,  811,   27,  286,   87,\n",
       "          1412, 1509,  106,  133, 2121,   99,  117, 2000,   75, 1413,   93,  447,\n",
       "           182,  108, 1530,  129,  739,  354, 1544,   26,  131, 2487,  320,  488,\n",
       "           362,  654, 1059, 1840, 2529,  113,   41,  259, 1411,  706,  454, 2180,\n",
       "           388,  129,  864,  447,  182,  108,  821,  102, 1996, 1118,  354, 1544,\n",
       "          1272,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0]]),\n",
       " 'length': tensor([328, 218])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader(train_dataset, batch_size=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель - генератор последовательностей на RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class LSTMLoop(nn.Module):\n",
    "    def __init__(self, dict_size, emb_size, rnn_num_units, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(dict_size, emb_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(emb_size, rnn_num_units, num_layers, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, dict_size)\n",
    "        \n",
    "    def forward(self, x, src_len):                          # BatchSize X InLen\n",
    "        \"\"\"src_len - параметр для упаковки эмбеддингов\"\"\"\n",
    "        embeddings = self.dropout(self.emb(x))              # BatchSize X InLen X EmbSize\n",
    "\n",
    "        packed_emb = pack_padded_sequence(embeddings, src_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_h_seq, _ = self.lstm(packed_emb)           # BatchSize X InLen X EmbSize (if no pack)\n",
    "        h_seq, _ = pad_packed_sequence(packed_h_seq, batch_first=True) \n",
    "\n",
    "        next_logits = self.hid_to_logits(h_seq)             # BatchSize X InLen X VocSize\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)      # BatchSize X InLen X VocSize\n",
    "        return next_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded...\n",
      "+----------------------+-----+------------+------------+---------------+---------+\n",
      "|   Modules/Tensors    | GPU |   Shape    | Parameters |      Type     | DataMem |\n",
      "+----------------------+-----+------------+------------+---------------+---------+\n",
      "|      emb.weight      |     | 3001 x 128 |   384128   | torch.float32 | 1536512 |\n",
      "|  lstm.weight_ih_l0   |     | 512 x 128  |   65536    | torch.float32 |  262144 |\n",
      "|  lstm.weight_hh_l0   |     | 512 x 128  |   65536    | torch.float32 |  262144 |\n",
      "|   lstm.bias_ih_l0    |     |    512     |    512     | torch.float32 |   2048  |\n",
      "|   lstm.bias_hh_l0    |     |    512     |    512     | torch.float32 |   2048  |\n",
      "|  lstm.weight_ih_l1   |     | 512 x 128  |   65536    | torch.float32 |  262144 |\n",
      "|  lstm.weight_hh_l1   |     | 512 x 128  |   65536    | torch.float32 |  262144 |\n",
      "|   lstm.bias_ih_l1    |     |    512     |    512     | torch.float32 |   2048  |\n",
      "|   lstm.bias_hh_l1    |     |    512     |    512     | torch.float32 |   2048  |\n",
      "| hid_to_logits.weight |     | 3001 x 128 |   384128   | torch.float32 | 1536512 |\n",
      "|  hid_to_logits.bias  |     |    3001    |    3001    | torch.float32 |  12004  |\n",
      "+----------------------+-----+------------+------------+---------------+---------+\n",
      "Total Trainable Params: 1035449\n",
      "Total memory (min): 4,044.72 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1035449"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = bpe.tokenizer.vocab_size() + 1      # +1 for <EOA>\n",
    "OUTPUT_DIM = bpe.tokenizer.vocab_size() + 1     # +1 for <EOA>\n",
    "EMB_DIM = 128\n",
    "HID_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.8\n",
    "\n",
    "model = LSTMLoop(INPUT_DIM, EMB_DIM, HID_DIM, NUM_LAYERS, DROPOUT)\n",
    "\n",
    "if not QUICK_RUN:\n",
    "    model.load_state_dict(torch.load(MODEL_NAME, map_location=device))\n",
    "    print(\"Loaded...\")\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizerW = optim.AdamW(optimizer_grouped_parameters, lr=5e-3)\n",
    "\n",
    "optimizer = optim.Adam(optimizer_grouped_parameters, lr=5e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест одного шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = nn.LSTM(EMB_DIM, HID_DIM, 2, batch_first=True)\n",
    "# emb = nn.Embedding(INPUT_DIM, EMB_DIM)\n",
    "# hid_to_logits = nn.Linear(HID_DIM, INPUT_DIM)\n",
    "\n",
    "# lstm.to(device), emb.to(device), hid_to_logits.to(device), \n",
    "\n",
    "# for batch in data_loader(train_dataset, 4):\n",
    "    \n",
    "#     # получение эмбеддингов\n",
    "#     print(f\"{batch['input_ids'].shape=}\")\n",
    "#     e = emb(batch[\"input_ids\"].to(device))\n",
    "#     print(f\"{e.shape=}\")\n",
    "\n",
    "#     # упаковка эмбеддингов (все потомки nn.Module понимают этот формат)\n",
    "#     print(f\"{batch['length']=}\")\n",
    "#     packed_embedded = nn.utils.rnn.pack_padded_sequence(e, batch[\"length\"], batch_first=True, enforce_sorted=False)\n",
    "\n",
    "#     # последнее, остальные состояния RNN (упакованные)\n",
    "#     packed_h_seq, _ = lstm.forward(packed_embedded)\n",
    "#     print(f\"{packed_h_seq.data.shape=}\")\n",
    "\n",
    "#     # распаковка ответа RNN\n",
    "#     h_seq, _ = nn.utils.rnn.pad_packed_sequence(packed_h_seq, batch_first=True) \n",
    "#     print(f\"{h_seq.shape=}\")\n",
    "    \n",
    "#     # последнее состояние - в логиты каждого токена\n",
    "#     next_logits = hid_to_logits(h_seq)\n",
    "#     print(f\"{next_logits.shape=}\")\n",
    "\n",
    "#     # логиты - в логарифмы шансов\n",
    "#     next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "#     print(f\"{next_logp.shape=}\")\n",
    "\n",
    "#     # сдвинутые на 1 относительно друг друга логарифмы шансов токенов и реальные токены\n",
    "#     pred_logp_next_tokens = next_logp[:, :-1].contiguous().view(-1, INPUT_DIM)  # (BatchSize * InLen) X VocSize \n",
    "#     actual_next_tokens = batch[\"input_ids\"][:, 1:].contiguous().view(-1)        # (BatchSize * InLen)\n",
    "#     print(f\"{pred_logp_next_tokens.shape=}, {actual_next_tokens.shape=}\")\n",
    "\n",
    "#     # наскольно не угадали\n",
    "#     loss = F.nll_loss(input=pred_logp_next_tokens.to(device), \n",
    "#                       target=actual_next_tokens.to(device))                     # scalar\n",
    "#     print(f\"{loss=}\")\n",
    "\n",
    "#     # расчет градиентов функции потерь\n",
    "#     loss.backward()\n",
    "\n",
    "#     # шаг по антиградиенту\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # обнулить градиенты, чтобы не складывались с пред.шагом\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = True\n",
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, steps=None, draw=True, draw_step=10, draw_win=None):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        next_logp = model.forward(batch[\"input_ids\"].to(device), batch[\"length\"])   # BatchSize X InLen X VocSize\n",
    "\n",
    "        pred_logp_next_tokens = next_logp[:, :-1].contiguous().view(-1, INPUT_DIM)  # (BatchSize * InLen) X VocSize \n",
    "        actual_next_tokens = batch[\"input_ids\"][:, 1:].contiguous().view(-1)        # (BatchSize * InLen)\n",
    "\n",
    "        loss = F.nll_loss(input=pred_logp_next_tokens.to(device), \n",
    "                          target=actual_next_tokens.to(device))                     # scalar\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        history.append(loss.detach().cpu().tolist())\n",
    "        if draw and (i + 1) % draw_step == 0:\n",
    "            clear_output(True)\n",
    "            start = max(0, len(history) - draw_win) if draw_win else 0\n",
    "            x_labels = list(range(start, len(history)))\n",
    "            plt.plot(x_labels, history[start:], label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        if steps and i == steps:\n",
    "            break\n",
    "            \n",
    "    return sum(history) / len(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.1158391461514015"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = data_loader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "train(model, train_loader, optimizerW, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):                         \n",
    "            next_logp = model.forward(batch[\"input_ids\"].to(device), batch[\"length\"])   # BatchSize X InLen X VocSize\n",
    "            pred_logp_next_tokens = next_logp[:, :-1].contiguous().view(-1, INPUT_DIM)  # (BatchSize * InLen) X VocSize \n",
    "            actual_next_tokens = batch[\"input_ids\"][:, 1:].contiguous().view(-1)        # (BatchSize * InLen)\n",
    "\n",
    "            loss = F.nll_loss(input=pred_logp_next_tokens.to(device), \n",
    "                            target=actual_next_tokens.to(device))                       # scalar\n",
    "\n",
    "            epoch_loss += loss.detach().cpu().tolist()\n",
    "        \n",
    "    return epoch_loss / len(iterator)                                                   # средняя на батч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_loader(train_dataset, BATCH_SIZE)\n",
    "val_loader = data_loader(val_dataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not SKIP:\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = train(model, train_loader, optimizerW, draw=False)\n",
    "        valid_loss = evaluate(model, val_loader)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), MODEL_NAME)\n",
    "            \n",
    "            \n",
    "        train_history.append(train_loss)\n",
    "        valid_history.append(valid_loss)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "    plt.plot(list(range(N_EPOCHS)), train_history, label='train loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.264 | Test PPL:  71.065 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_NAME, map_location=device))\n",
    "\n",
    "test_loader = data_loader(test_dataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_loss = evaluate(model, test_loader)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация заголовков\n",
    "- жадная генерация - не вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def generate(model, tokenizer, abstract, length=100):\n",
    "    model.eval()   # перевести в режим прогноза\n",
    "    \n",
    "    # к стартовой последовательности добавляется токен конца аннотации\n",
    "    x_sequence = tokenizer.encode([abstract])[\"input_ids\"][:-1] + [tokenizer.tokenizer.subword_to_id(tokenizer.eoa)]\n",
    "    seq_len = len(x_sequence)\n",
    "    x_sequence = torch.LongTensor([x_sequence]).to(device)               \n",
    "    \n",
    "    answer = []\n",
    "    for _ in range(length):\n",
    "        logp_next = model.forward(x_sequence, src_len=[seq_len]).detach().cpu()\n",
    "        p_next = F.softmax(logp_next, dim=-1).data.numpy()[0, -1]\n",
    "        \n",
    "        next_ix = np.argmax(np.array(p_next))       \n",
    "        answer.append(next_ix)\n",
    "        \n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1).to(device)\n",
    "    \n",
    "    return tokenizer.decode([answer])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference:\tlogarithmic components of the vacant set for random walk on a discrete   torus\n",
      "Candidate:\t\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reference:\tglobal regularity of wave maps iv. absence of stationary or self-similar   solutions in the energy class\n",
      "Candidate:\t\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reference:\tmoment estimators of the extreme value index for randomly censored data   in the weibull domain of attraction\n",
      "Candidate:\t\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "idx = np.random.choice(len(all_train_dataset.data), N)\n",
    "abstracts, titles = np.array(all_train_dataset.data.abstract)[idx], np.array(all_train_dataset.data.title)[idx]\n",
    "\n",
    "for abstract, title in zip(abstracts, titles):\n",
    "    print(f\"Reference:\\t{title}\\nCandidate:\\t{generate(model, bpe, abstract)}\\n\", end=\"\\n\"+\"-\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- лучевой поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference:\tclades and clans: a comparison study of two evolutionary models\n",
      "Candidate:\tthe yule-harding-kingman (yhk) model and the proportional to distinguishable arrangements (pda) model are two binary tree generating models that are widely used in evolutionary biology. understanding the distributions of clade sizes under these two models provides valuable insights into macro-evolutionary processes, and is important in hypothesis testing and bayesian analyses in phylogenetics. here we show that these distributions are log-convex, which implies that very large clades or very small clades are more likely to occur under these two models. moreover, we prove that there exists a critical value $\\kappa(n)$ for each $n\\geqslant 4$ such that for a given clade with size $k$, the probability that this clade is contained in a random tree with $n$ leaves generated under the yhk model is higher than that under the pda model if $1<k<\\kappa(n)$, and lower if $\\kappa(n)<k<n$. finally, we extend our results to binary unrooted trees, and obtain similar results for the distributions of clan sizes. the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "score=16.36\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reference:\tshape optimization of compliant pressure actuated cellular structures\n",
      "Candidate:\tbiologically inspired pressure actuated cellular structures can alter their shape through pressure variations. previous work introduced a computational framework for pressure actuated cellular structures which was limited to two cell rows and central cell corner hinges. this article rigorously extends these results by taking into account an arbitrary number of cell rows, a more complicated cell kinematics that includes hinge eccentricities and varying side lengths as well as rotational and axial cell side springs. the nonlinear effects of arbitrary cell deformations are fully considered. furthermore, the optimization is considerably improved by using a second-order approach. the presented framework enables the design of compliant pressure actuated cellular structures that can change their form from one shape to another within a set of one-dimensional c1 continuous functions. the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "score=18.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reference:\timplementing homomorphic encryption based secure feedback control for   physical systems\n",
      "Candidate:\tthis paper is about an encryption based approach to the secure implementation of feedback controllers for physical systems. specifically, paillier's homomorphic encryption is used to digitally implement a class of linear dynamic controllers, which includes the commonplace static gain and pid type feedback control laws as special cases. the developed implementation is amenable to field programmable gate array (fpga) realization. experimental results, including timing analysis and resource usage characteristics for different encryption key lengths, are presented for the realization of an inverted pendulum controller; as this is an unstable plant, the control is necessarily fast. the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "score=19.40\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reference:\tcross-diffusion modeling in macroeconomics\n",
      "Candidate:\tthis paper deals with the stability properties of a closed market, where capital and labour force are acting like a predator-prey system in population-dynamics. the spatial movement of the capital and labour force are taken into account by cross-diffusion effect. first, we are showing two possible ways for modeling this system in only one country's market (applying a simple functional response and a holling-type ratio-dependent response as well), examining the conditions of their stability properties. we extend the ratio-dependent model into two countries common market where two kind of cross-diffusion effects are present, and find those additional conditions, whose are necessary for the stability of the global common market besides the stability of each countries local markets. our four-dimensional model highlights that a hectic movement of the capital toward labour force can cause a turing instability. the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "score=17.61\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reference:\ton the minimum number of transmissions in single-hop wireless coding   networks\n",
      "Candidate:\tthe advent of network coding presents promising opportunities in many areas of communication and networking. it has been recently shown that network coding technique can significantly increase the overall throughput of wireless networks by taking advantage of their broadcast nature. in wireless networks, each transmitted packet is broadcasted within a certain area and can be overheard by the neighboring nodes. when a node needs to transmit packets, it employs the opportunistic coding approach that uses the knowledge of what the node's neighbors have heard in order to reduce the number of transmissions. with this approach, each transmitted packet is a linear combination of the original packets over a certain finite field. in this paper, we focus on the fundamental problem of finding the optimal encoding for the broadcasted packets that minimizes the overall number of transmissions. we show that this problem is np-complete over gf(2) and establish several fundamental properties of the optimal solution. we also propose a simple heuristic solution for the problem based on graph coloring and present some empirical results for random settings. the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "score=16.43\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from helpers.poetry import BeamGenerator\n",
    "\n",
    "beam_generate = BeamGenerator(model, bpe)\n",
    "\n",
    "def gen(seed_text, beamsize=5, return_hypotheses_n=1):\n",
    "    score, source_candidate = beam_generate(seed_text, beamsize=beamsize, return_hypotheses_n=return_hypotheses_n)[0]\n",
    "    candidate = source_candidate.split(\"<eoa>\")[-1]\n",
    "    return score, candidate\n",
    "\n",
    "N = 5\n",
    "idx = np.random.choice(len(all_train_dataset.data), N)\n",
    "abstracts, titles = np.array(all_train_dataset.data.abstract)[idx], np.array(all_train_dataset.data.title)[idx]\n",
    "\n",
    "for abstract, title in zip(abstracts, titles):\n",
    "    score, candidate = gen(abstract)\n",
    "    print(f\"Reference:\\t{title}\\nCandidate:\\t{candidate}\\n{score=:.2f}\", end=\"\\n\"+\"-\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С такой генерацией дальше нет смылса считать.\n",
    "- общая тематика улавливается (улавливалась, но модель не сохранилась), но конкретно референсные заголовки не выходят"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU-score\n",
    "\n",
    "- слабый baseline: 0.28204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_gram_weights = [0.3334, 0.3333, 0.3333]\n",
    "\n",
    "\n",
    "# sources, targets = all_train_dataset.data.abstract, all_train_dataset.data.title    # pd.Series\n",
    "\n",
    "# macro_bleu = 0\n",
    "# for i, src in enumerate(tqdm(sources)):\n",
    "#     candidate = generate(model, bpe, src).split()\n",
    "#     reference = targets.loc[i].split()\n",
    "#     macro_bleu += bleu_score([candidate], [reference], max_n=3, weights=n_gram_weights)\n",
    "\n",
    "# macro_bleu /= len(sources)\n",
    "\n",
    "# print(f'Macro-average BLEU (LSTM): {macro_bleu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission в Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация заголовков для тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMISSION_NAME = \"my2\"\n",
    "\n",
    "# titles = []\n",
    "# for abstract in tqdm(fin_test_src):\n",
    "#     title = generate(model, bpe, abstract).split()\n",
    "#     title = title if title else \"na\"\n",
    "#     titles.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем полученные заголовки в файл формата `<abstract>,<title>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df = pd.DataFrame({'abstract': fin_test_src, 'title': titles})\n",
    "\n",
    "# submission_df.to_csv(f\"./submission/{SUBMISSION_NAME}_submission/predicted_titles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью скрипта `generate_csv` приводим файл `submission_prediction.csv` в формат, необходимый для посылки в соревнование на Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.create_submission import generate_csv\n",
    "\n",
    "# generate_csv(input_file=f'./submission/{SUBMISSION_NAME}_submission/predicted_titles.csv', \n",
    "#              output_file=f'./submission/{SUBMISSION_NAME}_submission/submission.csv', \n",
    "#              voc_file=f'./datasets/vocs.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75291dc0307ea48294888123147845d2e15abd18d38848ca6ac05a6fe8c88425"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
