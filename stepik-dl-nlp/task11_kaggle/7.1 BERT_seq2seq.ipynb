{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- из данных убраны дубли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = f\"./datasets/train_clean.csv\"\n",
    "SMALL_CSV = f\"./cache/train.csv\"\n",
    "SCORING_CSV = f\"./datasets/test.csv\"\n",
    "\n",
    "USE_SMALL = True\n",
    "\n",
    "max_title = 36          # max 103, 3 сигмы 34 + 2\n",
    "max_abstract = 460      # max 1096, 3 сигмы 457 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-04a3546adcf83ebb\n",
      "Reusing dataset csv (/home/user1/.cache/huggingface/datasets/csv/default-04a3546adcf83ebb/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "arxiv_dataset = datasets.Dataset.from_csv(SMALL_CSV if USE_SMALL else TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 if USE_SMALL else 0.02\n",
    "arxiv_dataset = arxiv_dataset.train_test_split(test_size=test_size)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200, dict_keys(['abstract', 'title']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arxiv_dataset[\"train\"]), len(arxiv_dataset[\"test\"]), arxiv_dataset[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2e0a9ad90b647d2d\n",
      "Reusing dataset csv (/home/user1/.cache/huggingface/datasets/csv/default-2e0a9ad90b647d2d/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, dict_keys(['abstract']))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_dataset = datasets.Dataset.from_csv(SCORING_CSV)\n",
    "len(scoring_dataset), scoring_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# google/bert_uncased_L-8_H-512_A-8     # medium\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")   # small\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-8_H-512_A-8\")   # medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2070, 2146, 2146, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"some long long  long  long  long  long text\", max_length=5, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\" Длины последовательностей max = 1096 / 103. Берем какбе 3 сигмы:\n",
    "        - max_length=457 + 4\n",
    "        - max_length=34 + 2\n",
    "    \"\"\"\n",
    "\n",
    "    srcs = [prefix + doc for doc in examples[\"abstract\"]]\n",
    "    model_inputs = tokenizer(srcs, max_length=max_abstract, truncation=True) # max_length includes special tokens\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        trgs = tokenizer(examples[\"title\"], max_length=max_title, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = trgs[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.00ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.67ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_arxiv = arxiv_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['abstract', 'title', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']),\n",
       " \"we present in an unified and detailed way the nested bethe ansatz for closed spin chains based on y(gl(n)), y(gl(m|n)), u_q(gl(n)) or u_q(gl(m|n)) (super)algebras, with arbitrary representations (i.e. `spins') on each site of the chain. in particular, the case of indecomposable representations of superalgebras is studied. the construction extends and unifies the results already obtained for spin chains based on y(gl(n)) or u_q(gl(n)) and for some particular super-spin chains. we give the bethe equations and the form of the bethe vectors. the case of gl(2|1), gl(2|2$ and gl(4|4) superalgebras (that are related to ads/cft correspondence) is also detailed.\",\n",
       " 'nested bethe ansatz for \"all\" closed spin chains')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_arxiv[\"train\"][0].keys(), tokenized_arxiv[\"train\"][0][\"abstract\"], tokenized_arxiv[\"train\"][0][\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итераторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['abstract', 'title', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_arxiv['test'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7680,  7849,  4697,  1024,  1000, 21216,  1000,  4725,  2265,\n",
       "           2307,  4872,  2005,  6022, 29494,  2358, 11663, 20875, 24710,  1997,\n",
       "           3375, 16012, 15869,  4668,  6125,  1012,  2174,  1010,  2261,  6742,\n",
       "           5097,  1997, 21216,  2031,  2596,  1999,  1996,  3906,  2000,  3058,\n",
       "           1012,  2182,  1010,  2057,  4769,  2023,  3277,  2478,  1996,  1000,\n",
       "          13571,  2098, 21216,  9896,  1000,  1006, 20228,  2050,  1007,  1031,\n",
       "           1048,  1012,  1037,  1012,  5671,  1998,  1052,  1012, 24530,  1010,\n",
       "           1046,  1012, 18178,  2213,  1012,  6887,  7274,  1012,  8732,  1010,\n",
       "          14748, 10790,  2581,  1006,  2294,  1007,  1033,  1010,  1037,  3728,\n",
       "           1011,  3107,  4800, 15782,  2571, 21216,  3921,  1012,  2057,  2224,\n",
       "           1996, 20228,  2050,  2000,  8556,  2358, 11663, 20875,  3896,  1999,\n",
       "           2048,  2944, 16012, 15869,  4668,  6125,  1012,  1996,  6125,  2008,\n",
       "           2057,  5136,  2024,  3722,  2438,  2061,  2004,  2000,  2022,  7801,\n",
       "           2000,  2256, 26406,  2021, 12949,  3375,  2061,  2004,  2000,  2022,\n",
       "           3227,  4387,  1997,  2613,  6897,  3001,  1012,  2057, 10580,  2129,\n",
       "           1996, 20228,  2050,  4473,  2149,  2000, 24110, 27351, 11259,  3896,\n",
       "           1997,  2358, 11663, 20875,  3012,  1999,  2122,  3001,  2008,  2052,\n",
       "           2022,  3697,  2000,  2004, 17119, 18249,  4728,  2004,  2092,  2004,\n",
       "           2025,  1011,  2061,  1011, 11259, 15592,  2008,  2052, 10178,  4141,\n",
       "           1011,  2109,  1000,  6635,  1000,  2358, 11663, 20875,  4725,  1012,\n",
       "           2057,  2036, 19141,  5835, 18278,  2015,  2008,  2064, 17666,  2121,\n",
       "           1996,  3921,  1998,  4654,  6633, 28250,  1998,  6848,  2825,  9942,\n",
       "           2005, 27363,  2068,  1012,  3452,  1010,  2256,  6614,  2003,  2000,\n",
       "           4681,  1998,  9587, 29068,  3686,  2925,  5097,  1997, 21216,  2011,\n",
       "           4346,  9762, 11249,  1997,  1996,  6666,  1997,  1996,  4118,  2096,\n",
       "           2012,  1996,  2168,  2051,  3449, 14194,  8524,  3436, 15314,  2008,\n",
       "           2024,  2411,  8567,  1999,  3218,  1012,   102],\n",
       "         [  101,  7680,  7849,  4697,  1024,  1037,  2512, 13013,  7941,  9610,\n",
       "           1011,  2675,  4304,  2003,  8833,  1011,  9530, 27454,  2065,  1996,\n",
       "           3014,  1997,  4071,  2003, 16371,  1028,  1027,  1016,  1012,  2057,\n",
       "          13711,  2023,  2124,  2765,  2011,  4760,  2008,  1010,  2005,  2169,\n",
       "           1014,  1026, 16371,  1026,  1016,  1010,  2045,  6526, 23375,  1035,\n",
       "          16371,  1028,  1014,  2107,  2008,  1996,  9610,  1011,  2675,  2007,\n",
       "          16371,  5445,  1997,  4071,  1998,  2512, 13013,  7941,  3012, 16381,\n",
       "          23375,  2038,  1037, 16922,  4304,  2065, 23375,  1026,  1027, 23375,\n",
       "           1035, 16371,  1010,  1998,  2003, 12170,  1011, 16913,  2389,  4728,\n",
       "           1012,  1996,  4187, 23375,  1035, 16371,  2003,  7356,  2011,  2019,\n",
       "           8522,  5994,  1037,  6463,  1997,  6310,  2022, 21218,  4972,  1012,\n",
       "           2043,  2019,  4592,  5549,  6526,  2057, 18547, 10480, 19202,  2006,\n",
       "           2049,  3295,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0]]),\n",
       " 'labels': tensor([[  101, 24110, 27351,  2075,  2358, 11663, 20875,  3896,  1999, 16012,\n",
       "          15869,  4668,  6125,  2478, 13571,  2098, 21216,   102],\n",
       "         [  101,  1996,  4338,  1997,  1996,  2512, 13013,  7941,  9610,  1011,\n",
       "           2675,  4304,   102,     0,     0,     0,     0,     0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_batch(batch, padding_value=tokenizer.pad_token_id):\n",
    "   \"\"\"Дополняем батч паддингом до размера максимального в батче\"\"\" \n",
    "\n",
    "   src_tuple_of_seqs = tuple(map(lambda x: torch.LongTensor(x[\"input_ids\"]), batch))\n",
    "   src_att_tuple_of_seqs = tuple(map(lambda x: torch.LongTensor(x[\"attention_mask\"]), batch))\n",
    "   trg_tuple_of_seqs = tuple(map(lambda x: torch.LongTensor(x[\"labels\"]), batch))\n",
    "   padded_sources = torch.nn.utils.rnn.pad_sequence(src_tuple_of_seqs, \n",
    "                                                    padding_value=padding_value, batch_first=True)\n",
    "   padded_srs_atts = torch.nn.utils.rnn.pad_sequence(src_att_tuple_of_seqs, \n",
    "                                                    padding_value=padding_value, batch_first=True)\n",
    "   padded_targets = torch.nn.utils.rnn.pad_sequence(trg_tuple_of_seqs, \n",
    "                                                    padding_value=padding_value, batch_first=True)\n",
    "   return {\"input_ids\": padded_sources, \n",
    "           \"attention_mask\": padded_srs_atts,\n",
    "           \"labels\": padded_targets}\n",
    "\n",
    "def data_loader(dataset, batch_size, shuffle=True, **kwargs):\n",
    "    return torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=shuffle, \n",
    "                                       collate_fn=collate_batch,\n",
    "                                       num_workers=0,\n",
    "                                       **kwargs)\n",
    "\n",
    "next(iter(data_loader(tokenized_arxiv['test'], batch_size=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-512_A-8 were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at google/bert_uncased_L-8_H-512_A-8 and are newly initialized: ['bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.key.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 512)\n",
       "        (token_type_embeddings): Embedding(2, 512)\n",
       "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "# google bert-small https://huggingface.co/google/bert_uncased_L-4_H-512_A-8\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained('google/bert_uncased_L-8_H-512_A-8', 'google/bert_uncased_L-8_H-512_A-8') # medium\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении тагрет в модель подается кроме последнего токена, при валидации/генрации - кроме первого.\n",
    "\n",
    "Поэтому для генерации сид-фраза должна начинаться с того токена, на котором модель обучалась, в данном случае это первый токен берта `[CLS]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+-----+-------------+------------+---------------+----------+\n",
      "|                           Modules/Tensors                           | GPU |    Shape    | Parameters |      Type     | DataMem  |\n",
      "+---------------------------------------------------------------------+-----+-------------+------------+---------------+----------+\n",
      "|              encoder.embeddings.word_embeddings.weight              |  +  | 30522 x 512 |  15627264  | torch.float32 | 62509056 |\n",
      "|            encoder.embeddings.position_embeddings.weight            |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.embeddings.token_type_embeddings.weight           |  +  |   2 x 512   |    1024    | torch.float32 |   4096   |\n",
      "|                 encoder.embeddings.LayerNorm.weight                 |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|                  encoder.embeddings.LayerNorm.bias                  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.0.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.0.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.0.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.0.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.0.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.0.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.0.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.0.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.0.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.0.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.0.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.0.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.0.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.0.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.0.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.0.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.1.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.1.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.1.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.1.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.1.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.1.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.1.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.1.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.1.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.1.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.1.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.1.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.1.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.1.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.1.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.1.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.2.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.2.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.2.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.2.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.2.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.2.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.2.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.2.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.2.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.2.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.2.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.2.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.2.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.2.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.2.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.2.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.3.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.3.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.3.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.3.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.3.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.3.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.3.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.3.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.3.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.3.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.3.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.3.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.3.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.3.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.3.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.3.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.4.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.4.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.4.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.4.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.4.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.4.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.4.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.4.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.4.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.4.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.4.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.4.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.4.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.4.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.4.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.4.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.5.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.5.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.5.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.5.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.5.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.5.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.5.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.5.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.5.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.5.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.5.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.5.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.5.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.5.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.5.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.5.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.6.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.6.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.6.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.6.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.6.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.6.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.6.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.6.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.6.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.6.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.6.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.6.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.6.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.6.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.6.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.6.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.7.attention.self.query.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.7.attention.self.query.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.7.attention.self.key.weight          |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|           encoder.encoder.layer.7.attention.self.key.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         encoder.encoder.layer.7.attention.self.value.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|          encoder.encoder.layer.7.attention.self.value.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        encoder.encoder.layer.7.attention.output.dense.weight        |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         encoder.encoder.layer.7.attention.output.dense.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      encoder.encoder.layer.7.attention.output.LayerNorm.weight      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       encoder.encoder.layer.7.attention.output.LayerNorm.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          encoder.encoder.layer.7.intermediate.dense.weight          |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|           encoder.encoder.layer.7.intermediate.dense.bias           |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|             encoder.encoder.layer.7.output.dense.weight             |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|              encoder.encoder.layer.7.output.dense.bias              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           encoder.encoder.layer.7.output.LayerNorm.weight           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            encoder.encoder.layer.7.output.LayerNorm.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|                     encoder.pooler.dense.weight                     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|                      encoder.pooler.dense.bias                      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|            decoder.bert.embeddings.word_embeddings.weight           |  +  | 30522 x 512 |  15627264  | torch.float32 | 62509056 |\n",
      "|          decoder.bert.embeddings.position_embeddings.weight         |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.embeddings.token_type_embeddings.weight        |  +  |   2 x 512   |    1024    | torch.float32 |   4096   |\n",
      "|               decoder.bert.embeddings.LayerNorm.weight              |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|                decoder.bert.embeddings.LayerNorm.bias               |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.0.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.0.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.0.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.0.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.0.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.0.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.0.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.0.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.0.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.0.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.0.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.0.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.0.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.0.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.0.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.0.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.0.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.0.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.0.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.0.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.0.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.0.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.1.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.1.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.1.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.1.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.1.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.1.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.1.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.1.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.1.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.1.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.1.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.1.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.1.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.1.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.1.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.1.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.1.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.1.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.1.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.1.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.1.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.1.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.2.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.2.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.2.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.2.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.2.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.2.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.2.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.2.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.2.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.2.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.2.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.2.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.2.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.2.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.2.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.2.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.2.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.2.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.2.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.2.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.2.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.2.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.3.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.3.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.3.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.3.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.3.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.3.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.3.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.3.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.3.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.3.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.3.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.3.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.3.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.3.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.3.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.3.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.3.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.3.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.3.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.3.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.3.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.3.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.4.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.4.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.4.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.4.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.4.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.4.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.4.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.4.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.4.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.4.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.4.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.4.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.4.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.4.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.4.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.4.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.4.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.4.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.4.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.4.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.4.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.4.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.5.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.5.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.5.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.5.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.5.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.5.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.5.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.5.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.5.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.5.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.5.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.5.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.5.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.5.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.5.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.5.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.5.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.5.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.5.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.5.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.5.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.5.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.6.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.6.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.6.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.6.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.6.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.6.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.6.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.6.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.6.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.6.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.6.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.6.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.6.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.6.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.6.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.6.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.6.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.6.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.6.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.6.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.6.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.6.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.7.attention.self.query.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.7.attention.self.query.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.7.attention.self.key.weight       |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|         decoder.bert.encoder.layer.7.attention.self.key.bias        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|       decoder.bert.encoder.layer.7.attention.self.value.weight      |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|        decoder.bert.encoder.layer.7.attention.self.value.bias       |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|      decoder.bert.encoder.layer.7.attention.output.dense.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|       decoder.bert.encoder.layer.7.attention.output.dense.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight   |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.7.crossattention.self.query.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.7.crossattention.self.query.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|     decoder.bert.encoder.layer.7.crossattention.self.key.weight     |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|      decoder.bert.encoder.layer.7.crossattention.self.key.bias      |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|    decoder.bert.encoder.layer.7.crossattention.self.value.weight    |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|     decoder.bert.encoder.layer.7.crossattention.self.value.bias     |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|   decoder.bert.encoder.layer.7.crossattention.output.dense.weight   |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|    decoder.bert.encoder.layer.7.crossattention.output.dense.bias    |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "| decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|  decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias  |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|        decoder.bert.encoder.layer.7.intermediate.dense.weight       |  +  |  2048 x 512 |  1048576   | torch.float32 | 4194304  |\n",
      "|         decoder.bert.encoder.layer.7.intermediate.dense.bias        |  +  |     2048    |    2048    | torch.float32 |   8192   |\n",
      "|           decoder.bert.encoder.layer.7.output.dense.weight          |  +  |  512 x 2048 |  1048576   | torch.float32 | 4194304  |\n",
      "|            decoder.bert.encoder.layer.7.output.dense.bias           |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|         decoder.bert.encoder.layer.7.output.LayerNorm.weight        |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.bert.encoder.layer.7.output.LayerNorm.bias         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|                     decoder.cls.predictions.bias                    |  +  |    30522    |   30522    | torch.float32 |  122088  |\n",
      "|            decoder.cls.predictions.transform.dense.weight           |  +  |  512 x 512  |   262144   | torch.float32 | 1048576  |\n",
      "|             decoder.cls.predictions.transform.dense.bias            |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|          decoder.cls.predictions.transform.LayerNorm.weight         |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "|           decoder.cls.predictions.transform.LayerNorm.bias          |  +  |     512     |    512     | torch.float32 |   2048   |\n",
      "+---------------------------------------------------------------------+-----+-------------+------------+---------------+----------+\n",
      "Total Trainable Params: 91191098\n",
      "Total memory (min): 356,215.23 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91191098"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers.utils import count_parameters\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "MODEL_NAME = \"./models/bert2bert-medium.pt\"\n",
    "MODEL_PATH = \"./bert2bert-base-results\"\n",
    "BATCH_SIZE = 4\n",
    "ACCUMULATION_STEPS = 8\n",
    "\n",
    "model.train()\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "save_step = 500\n",
    "\n",
    "train_ds = data_loader(tokenized_arxiv['train'], batch_size=BATCH_SIZE)\n",
    "val_ds = data_loader(tokenized_arxiv['test'], batch_size=BATCH_SIZE)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for step, batch in enumerate(train_ds):\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids=batch[\"input_ids\"].to(device), # маски (по-идее) само сделает\n",
    "                        labels=batch[\"labels\"].to(device))\n",
    "        \n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "        train_loss_set.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        if (step + 1) % ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        clear_output(True)\n",
    "        #plt.cla()\n",
    "        plt.plot(train_loss_set)\n",
    "        plt.title(f\"Training loss. Epoch {epoch}\")\n",
    "        plt.xlabel(f\"Batch {step}\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "        if step != 0 and step % save_step == 0:\n",
    "            model.save_pretrained(\"bert2bert\")\n",
    "            torch.save(model.state_dict(), MODEL_NAME)\n",
    "\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем вроде сходится"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(example):\n",
    "    input_ids = tokenizer(prefix + example[\"abstract\"], \n",
    "                        max_length=max_abstract, \n",
    "                        truncation=True, \n",
    "                        return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "    outputs = model.generate(input_ids.to(device))\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('in most illiquid markets, there is no obvious proxy for the market price of an asset. the european corporate bond market is an archetypal example of such an illiquid market where mid-prices can only be estimated with a statistical model. in this otc market, dealers / market makers only have access, indeed, to partial information about the market. in real time, they know the price associated with their trades on the dealer-to-dealer (d2d) and dealer-to-client (d2c) markets, they know the result of the requests for quotes (rfq) they answered, and they have access to composite prices (e.g., bloomberg cbbt). this paper presents a bayesian method for estimating the mid-price of corporate bonds by using the real-time information available to a dealer. this method relies on recent ideas coming from the particle filtering / sequential monte-carlo literature.',\n",
       " 'mid-price estimation for european corporate bonds: a particle filtering   approach',\n",
       " 'of of - - - - - - - - - - - - - - - -')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "arxiv_dataset[\"test\"][n][\"abstract\"], arxiv_dataset[\"test\"][n][\"title\"], generate(arxiv_dataset[\"test\"][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 42\n",
    "arxiv_dataset[\"test\"][n][\"abstract\"], arxiv_dataset[\"test\"][n][\"title\"], generate(arxiv_dataset[\"test\"][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU-score\n",
    "\n",
    "Самоделки:\n",
    "- 0.02457 (словарь 6152, по 5 эпох по 5r-4, 1e-3, min.val.loss = 3.875) \n",
    "- **0.19204** (словарь 60 тыс. ~15 эпох с шагом 5e-4 -> 5e-5, min.val.loss = 2.289)\n",
    "- 0.12601 (словарь 84 тыс. много разных эпох, сходится плохо, min.val.loss = 3.305)\n",
    "- 0.10644 (BPE, словарь 16 тыс., много разных эпох, сходится плохо, min.val.loss = 3.8)\n",
    "\n",
    "T5-small\n",
    "- BLEU-score: **0.044...** 1% тюнинг\n",
    "- BLEU-score: **0.16563** (3 эпохи - 2,5 часа RTX2060 6Gb)\n",
    "\n",
    "T5-base\n",
    "- BLEU-score: **0.07422** (без обучения)\n",
    "- обучение не тянет...\n",
    "\n",
    "BART-base\n",
    "- BLEU-score: **0.17743** 1% тюнинг\n",
    "- BLEU-score: **0.17984** (1.43 эпохи - 2,5 часа RTX2060 6Gb)\n",
    "- BLEU-score: **0.19266** (2 эпохи)\n",
    "\n",
    "bert2bert-small (4 слоя, 8 голов внимания, 512 эмбеддинг)\n",
    "- BLEU-score: **0.00524** 1% тюнинг\n",
    "- BLEU-score: **0.04807** (2 эпохи) чето не то....\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "candidates = []\n",
    "references = []\n",
    "for example in tqdm(tokenized_arxiv[\"test\"]):\n",
    "    candidates.append(generate(example).split())\n",
    "    references.append([example[\"title\"].split()])\n",
    "\n",
    "score = bleu_score(candidates, references, max_n=3, weights=[1/3]*3)\n",
    "\n",
    "print('BLEU-score: {0:.5f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepik score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NAME = \"bert2bert-small\" if USE_SMALL else \"bert2bert-small-tune\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация заголовков для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "abstracts = []\n",
    "titles = []\n",
    "\n",
    "for example in tqdm(scoring_dataset):\n",
    "    abstracts.append(example[\"abstract\"])\n",
    "    titles.append(generate(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, например"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts[1], titles[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем полученные заголовки в файл формата `<abstract>,<title>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\n",
    "submission_df.to_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"title\"].apply(lambda x: len(str(x).split())).describe()[[\"mean\",\"std\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью скрипта `generate_csv` приводим файл `submission_prediction.csv` в формат, необходимый для отправки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.create_submission import generate_csv\n",
    "\n",
    "generate_csv(input_file=f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\", \n",
    "             output_file=f'./submission/submission_{SUBMISSION_NAME}.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С учетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"./datasets/train.csv\")\n",
    "submission_df = pd.read_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\")\n",
    "\n",
    "intersect_idx = np.intersect1d(submission_df[\"abstract\"].str.lower(), train_df[\"abstract\"].str.lower(), return_indices=True)\n",
    "\n",
    "submission_df.loc[intersect_idx[1], 'title'] = train_df.loc[intersect_idx[2], 'title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.create_submission import generate_csv\n",
    "\n",
    "submission_df.to_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}_fake.csv\", index=False)\n",
    "\n",
    "generate_csv(input_file=f\"./submission/predicted_titles_{SUBMISSION_NAME}_fake.csv\", \n",
    "             output_file=f'./submission/submission_{SUBMISSION_NAME}_fake.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'./submission/submission_{SUBMISSION_NAME}_fake.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5-small:\n",
    "- **Score: 0.26174** 1% tuning\n",
    "- **Score: 0.34497** tuning 3 эпохи\n",
    "- **Score: 0.51810** + добавление правильных меток из трейна\n",
    "\n",
    "T5-base:\n",
    "- **Score: 0.20510** w/o tuning\n",
    "- для обучения с имеющейся длиной последовательности не хватает памяти GPU\n",
    "\n",
    "BART-base\n",
    "- **Score: 0.33851** 1% tuning\n",
    "- **Score: 0.39536** tuning 1,5 эпохи\n",
    "- **Score: 0.54804** + добавление правильных меток из трейна\n",
    "- **Score: 0.56782** 2 эпохи с накопление градиента (вот и в топ-10)\n",
    "- ... дальше не интересно"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d00ba0b92f737b23b3e678e3a3ceb3fe4e948ad1ab95d9c6fdcbb4b4ec65f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
