{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Кто-то заметил](https://www.kaggle.com/code/kashnitsky/arxiv-title-generation-dumb-baseline/notebook), что в тестовой выборке много дублей с тренировочной, да и в тренировочной тоже дублируются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from helpers.create_submission import generate_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135000, 1000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./datasets/train.csv\")\n",
    "test_df = pd.read_csv(\"./datasets/test.csv\")\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убрать дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105603"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти пересечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_abstracts = train_df['abstract'].str.lower()\n",
    "test_abstracts = test_df['abstract'].str.lower()\n",
    "\n",
    "intersect_idx = np.intersect1d(test_abstracts, train_abstracts, return_indices=True)\n",
    "\n",
    "len(intersect_idx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве $H_0$ для заголовка - первого предложение резюме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_sentence(text, max_words=40):\n",
    "    return \" \".join(text.strip().split('.')[0].split()[:max_words])\n",
    "\n",
    "submission_df = pd.DataFrame({\"abstract\":test_df['abstract'],\n",
    "                              \"title\":test_df['abstract'].apply(extract_first_sentence)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменить заголовки для пересечения тестовой и тренировочной выборки на настоящие заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.loc[intersect_idx[1], 'title'] = train_df.loc[intersect_idx[2], 'title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка такой $H_0$\n",
    "- чистой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0734657347202301"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "sample_df = train_df.sample(1000)\n",
    "sample_df[\"candidate\"] = sample_df['abstract'].apply(extract_first_sentence)\n",
    "\n",
    "candidat_corpus = [c.split() for c in sample_df[\"candidate\"].tolist()]\n",
    "ref_corpus = [[r.split()] for r in sample_df[\"title\"].tolist()]\n",
    "\n",
    "bleu_score(candidat_corpus, ref_corpus, max_n=3, weights=[1/3]*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- с заменой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29631006717681885"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = train_df.sample(1000)\n",
    "sample_df[\"candidate\"] = sample_df['abstract'].apply(extract_first_sentence)\n",
    "\n",
    "bug_idx = sample_df[\"candidate\"].sample(430).index\n",
    "sample_df.loc[bug_idx, \"candidate\"] = sample_df.loc[bug_idx, \"title\"].values\n",
    "\n",
    "candidat_corpus = [c.split() for c in sample_df[\"candidate\"].tolist()]\n",
    "ref_corpus = [[r.split()] for r in sample_df[\"title\"].tolist()]\n",
    "\n",
    "bleu_score(candidat_corpus, ref_corpus, max_n=3, weights=[1/3]*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"bug\"\n",
    "\n",
    "submission_df.to_csv(f\"./submission/{PREFIX}_submission/predicted_titles.csv\", index=False)\n",
    "\n",
    "generate_csv(input_file=f'./submission/{PREFIX}_submission/predicted_titles.csv', \n",
    "             output_file=f'./submission/{PREFIX}_submission/submission.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Другой вариант**\n",
    "- заменить на последовательность самых частотных токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>430</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>discussion of \"instrumental variables: an econ...</td>\n",
       "      <td>some contra-arguments for the use of stable di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract                                              title\n",
       "count                                                 433                                                433\n",
       "unique                                                430                                                433\n",
       "top     discussion of \"instrumental variables: an econ...  some contra-arguments for the use of stable di...\n",
       "freq                                                    3                                                  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples_from_train = set(train_df['abstract']).intersection(set(test_df['abstract']))\n",
    "wtf_df = train_df[train_df['abstract'].isin(test_samples_from_train)]\n",
    "wtf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13758</th>\n",
       "      <td>discussion of \"instrumental variables: an econ...</td>\n",
       "      <td>ace bounds; sems with equilibrium conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24872</th>\n",
       "      <td>discussion of \"instrumental variables: an econ...</td>\n",
       "      <td>think globally, act globally: an epidemiologis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101295</th>\n",
       "      <td>discussion of \"instrumental variables: an econ...</td>\n",
       "      <td>causal graphs: addressing the confounding prob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract                                              title\n",
       "13758   discussion of \"instrumental variables: an econ...       ace bounds; sems with equilibrium conditions\n",
       "24872   discussion of \"instrumental variables: an econ...  think globally, act globally: an epidemiologis...\n",
       "101295  discussion of \"instrumental variables: an econ...  causal graphs: addressing the confounding prob..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugged_title = wtf_df.abstract.mode()[0]\n",
    "# https://arxiv.org/pdf/1410.0163.pdf\n",
    "wtf_df[wtf_df['abstract'] == bugged_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>to appear to mcmc handbook, s. p. brooks, a. g...</td>\n",
       "      <td>reversible jump markov chain monte carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90696</th>\n",
       "      <td>to appear to mcmc handbook, s. p. brooks, a. g...</td>\n",
       "      <td>likelihood-free markov chain monte carlo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract                                     title\n",
       "11430  to appear to mcmc handbook, s. p. brooks, a. g...  reversible jump markov chain monte carlo\n",
       "90696  to appear to mcmc handbook, s. p. brooks, a. g...  likelihood-free markov chain monte carlo"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf_df = wtf_df[wtf_df['abstract'] != bugged_title]\n",
    "uncertain_title = wtf_df.abstract.mode()[0]\n",
    "wtf_df[wtf_df['abstract'] == uncertain_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf_df = wtf_df[wtf_df['abstract'] != uncertain_title].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean title length is 9.523820346012897\n",
      "BEST TITLE EVER:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'of the and in for a on with to model'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "words = [st.split() for st in train_df['title'].values]\n",
    "words = [w for ttl in words for w in ttl]\n",
    "\n",
    "mean_title_length = np.mean(np.asarray([len(st.split()) for st in train_df['title'].values]))\n",
    "print('Mean title length is', mean_title_length)\n",
    "\n",
    "most_frequently_words = collections.Counter(words).most_common()[:round(mean_title_length)]\n",
    "nan_fill_value = ' '.join([el[0] for el in most_frequently_words])\n",
    "print('BEST TITLE EVER:')\n",
    "nan_fill_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.merge(test_df, wtf_df, on='abstract', how='left').fillna(nan_fill_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка такой $H_0$\n",
    "- чистой (фигня, bleu это не проведет, F1-меру - наверно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = train_df.sample(1000)\n",
    "sample_df[\"candidate\"] = nan_fill_value\n",
    "\n",
    "candidat_corpus = [c.split() for c in sample_df[\"candidate\"].tolist()]\n",
    "ref_corpus = [[r.split()] for r in sample_df[\"title\"].tolist()]\n",
    "\n",
    "bleu_score(candidat_corpus, ref_corpus, max_n=3, weights=[1/3]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['of', 'the', 'and', 'in', 'for', 'a', 'on', 'with', 'to', 'model'],\n",
       " [['search', 'for', 'rare', 'b-meson', 'decays', 'at', 'cdf']])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidat_corpus[0], ref_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"bug\"\n",
    "\n",
    "submission_df.to_csv(f\"./submission/{PREFIX}_submission/predicted_titles2.csv\", index=False)\n",
    "\n",
    "generate_csv(input_file=f'./submission/{PREFIX}_submission/predicted_titles2.csv', \n",
    "             output_file=f'./submission/{PREFIX}_submission/submission2.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75291dc0307ea48294888123147845d2e15abd18d38848ca6ac05a6fe8c88425"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
