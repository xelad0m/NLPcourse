{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе туториала `transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- из данных убраны дубли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = f\"./datasets/train_clean.csv\"\n",
    "SMALL_CSV = f\"./cache/train.csv\"\n",
    "SCORING_CSV = f\"./datasets/test.csv\"\n",
    "\n",
    "USE_SMALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасеты\n",
    "\n",
    "- пакет huggingface datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-044aa5b2537bb910\n",
      "Reusing dataset csv (/home/user1/.cache/huggingface/datasets/csv/default-044aa5b2537bb910/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "arxiv_dataset = datasets.Dataset.from_csv(SMALL_CSV if USE_SMALL else TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 if USE_SMALL else 0.02\n",
    "arxiv_dataset = arxiv_dataset.train_test_split(test_size=test_size)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103490, 2113, dict_keys(['abstract', 'title']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arxiv_dataset[\"train\"]), len(arxiv_dataset[\"test\"]), arxiv_dataset[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2e0a9ad90b647d2d\n",
      "Reusing dataset csv (/home/user1/.cache/huggingface/datasets/csv/default-2e0a9ad90b647d2d/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, dict_keys(['abstract']))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_dataset = datasets.Dataset.from_csv(SCORING_CSV)\n",
    "len(scoring_dataset), scoring_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")   # 1.3 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Почти все последовательности без обрезки: max = 1096 / 103\n",
    "        - max_length=1024\n",
    "        - max_length=128\n",
    "    \"\"\"\n",
    "\n",
    "    srcs = [prefix + doc for doc in examples[\"abstract\"]]\n",
    "    model_inputs = tokenizer(srcs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        trgs = tokenizer(examples[\"title\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = trgs[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:34<00:00,  2.99ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.28ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_arxiv = arxiv_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['abstract', 'title', 'input_ids', 'attention_mask', 'labels']),\n",
       " 'a version of the virial theorem, which takes into account the effects of the non-compact extra-dimensions, is derived in the framework of the brane world models. in the braneworld scenario, the four dimensional effective einstein equation has some extra terms, called dark radiation and dark pressure, respectively, which arise from the embedding of the 3-brane in the bulk. to derive the generalized virial theorem we use a method based on the collisionless boltzmann equation. the dark radiation term generates an equivalent mass term (the dark mass), which gives an effective contribution to the gravitational energy. this term may account for the well-known virial theorem mass discrepancy in actual clusters of galaxies. an approximate solution of the vacuum field equations on the brane, corresponding to weak gravitational fields, is also obtained, and the expressions for the dark radiation and dark mass are derived. the qualitative behavior of the dark mass is similar to that of the observed virial mass in clusters of galaxies. we compare our model with the observational data for galaxy clusters, and we express all the physical parameters of the model in terms of observable quantities. in particular, we predict that the dark mass must extend far beyond the presently considered virial radius. the behavior of the galaxy cluster velocity dispersion in brane world models is also considered. therefore the study of the matter distribution and velocity dispersion at the extragalactic scales could provide an efficient method for testing the multi-dimensional physical models.',\n",
       " 'the virial theorem and the dynamics of clusters of galaxies in the brane   world models')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_arxiv[\"train\"][0].keys(), tokenized_arxiv[\"train\"][0][\"abstract\"], tokenized_arxiv[\"train\"][0][\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)    # if no train else trainer sends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./BART-base-results\",\n",
    "    optim=\"adamw_torch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    weight_decay=0.01,\n",
    "    # logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3*8,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_arxiv[\"train\"],\n",
    "    eval_dataset=tokenized_arxiv[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from ./BART-base-results/checkpoint-74000).\n",
      "The following columns in the training set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: title, abstract. If title, abstract are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 103490\n",
      "  Num Epochs = 24\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 155232\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 11\n",
      "  Continuing training from global step 74000\n",
      "  Will skip the first 11 epochs then the first 22816 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n",
      "Skipping the first batches: 100%|██████████| 22816/22816 [00:24<00:00, 912.70it/s]\n",
      "\n",
      "\u001b[A                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7665, 'learning_rate': 1.0405457637600496e-05, 'epoch': 11.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                      Saving model checkpoint to ./BART-base-results/checkpoint-75000\n",
      "Configuration saved in ./BART-base-results/checkpoint-75000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7499, 'learning_rate': 1.0341037930323644e-05, 'epoch': 11.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./BART-base-results/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in ./BART-base-results/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in ./BART-base-results/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [BART-base-results/checkpoint-72000] due to args.save_total_limit\n",
      "\n",
      "\u001b[A                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7542, 'learning_rate': 1.0276618223046794e-05, 'epoch': 11.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                      Saving model checkpoint to ./BART-base-results/checkpoint-76000\n",
      "Configuration saved in ./BART-base-results/checkpoint-76000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7637, 'learning_rate': 1.0212198515769944e-05, 'epoch': 11.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./BART-base-results/checkpoint-76000/pytorch_model.bin\n",
      "tokenizer config file saved in ./BART-base-results/checkpoint-76000/tokenizer_config.json\n",
      "Special tokens file saved in ./BART-base-results/checkpoint-76000/special_tokens_map.json\n",
      "Deleting older checkpoint [BART-base-results/checkpoint-73000] due to args.save_total_limit\n",
      "\n",
      "\u001b[A                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7183, 'learning_rate': 1.0147907647907648e-05, 'epoch': 11.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                      Saving model checkpoint to ./BART-base-results/checkpoint-77000\n",
      "Configuration saved in ./BART-base-results/checkpoint-77000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7281, 'learning_rate': 1.0083487940630798e-05, 'epoch': 11.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./BART-base-results/checkpoint-77000/pytorch_model.bin\n",
      "tokenizer config file saved in ./BART-base-results/checkpoint-77000/tokenizer_config.json\n",
      "Special tokens file saved in ./BART-base-results/checkpoint-77000/special_tokens_map.json\n",
      "Deleting older checkpoint [BART-base-results/checkpoint-74000] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user1/projects/stepik.org/DataScience/Нейронные сети и обработка текста/stepik-dl-nlp/task11_kaggle/7. BART_fine-tune.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/user1/projects/stepik.org/DataScience/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20%D0%B8%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0/stepik-dl-nlp/task11_kaggle/7.%20BART_fine-tune.ipynb#ch0000021?line=0'>1</a>\u001b[0m tqdm\u001b[39m.\u001b[39m_instances\u001b[39m.\u001b[39mclear()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user1/projects/stepik.org/DataScience/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B5%D1%82%D0%B8%20%D0%B8%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0/stepik-dl-nlp/task11_kaggle/7.%20BART_fine-tune.ipynb#ch0000021?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(resume_from_checkpoint\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/envs/py310/lib64/python3/site-packages/transformers/trainer.py:1426\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1420'>1421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1421'>1422</a>\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1423'>1424</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1424'>1425</a>\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m-> <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1425'>1426</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1426'>1427</a>\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1427'>1428</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1428'>1429</a>\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1429'>1430</a>\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/trainer.py?line=1430'>1431</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/py310/lib64/python3/site-packages/transformers/utils/import_utils.py:372\u001b[0m, in \u001b[0;36mis_torch_tpu_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/utils/import_utils.py?line=369'>370</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/utils/import_utils.py?line=370'>371</a>\u001b[0m \u001b[39m# This test is probably enough, but just in case, we unpack a bit.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/utils/import_utils.py?line=371'>372</a>\u001b[0m \u001b[39mif\u001b[39;00m importlib\u001b[39m.\u001b[39;49mutil\u001b[39m.\u001b[39;49mfind_spec(\u001b[39m\"\u001b[39;49m\u001b[39mtorch_xla\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/utils/import_utils.py?line=372'>373</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user1/envs/py310/lib64/python3/site-packages/transformers/utils/import_utils.py?line=373'>374</a>\u001b[0m \u001b[39mif\u001b[39;00m importlib\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mfind_spec(\u001b[39m\"\u001b[39m\u001b[39mtorch_xla.core\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib64/python3.10/importlib/util.py:103\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.10/importlib/util.py?line=100'>101</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib64/python3.10/importlib/util.py?line=101'>102</a>\u001b[0m         parent_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib64/python3.10/importlib/util.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _find_spec(fullname, parent_path)\n\u001b[1;32m    <a href='file:///usr/lib64/python3.10/importlib/util.py?line=103'>104</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib64/python3.10/importlib/util.py?line=104'>105</a>\u001b[0m     module \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[fullname]\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1572\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:128\u001b[0m, in \u001b[0;36m_path_join\u001b[0;34m(*path_parts)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(example):\n",
    "    input_ids = tokenizer(prefix + example[\"abstract\"], \n",
    "                        max_length=1024, \n",
    "                        truncation=True, \n",
    "                        return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "    outputs = model.generate(input_ids.to(device))\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('we provide an approach for learning deep neural net representations of models described via conditional moment restrictions. conditional moment restrictions are widely used, as they are the language by which social scientists describe the assumptions they make to enable causal inference. we formulate the problem of estimating the underling model as a zero-sum game between a modeler and an adversary and apply adversarial training. our approach is similar in nature to generative adversarial networks (gan), though here the modeler is learning a representation of a function that satisfies a continuum of moment conditions and the adversary is identifying violating moments. we outline ways of constructing effective adversaries in practice, including kernels centered by k-means clustering, and random forests. we examine the practical performance of our approach in the setting of non-parametric instrumental variable regression.',\n",
       " 'adversarial generalized method of moments',\n",
       " 'learning conditional moment restrictions')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "arxiv_dataset[\"test\"][n][\"abstract\"], arxiv_dataset[\"test\"][n][\"title\"], generate(arxiv_dataset[\"test\"][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('an increasing number of studies use the spectrum of cardiac signals for analyzing the spatiotemporal dynamics of complex cardiac arrhythmias. however, the relationship between the spectrum of cardiac signals and the spatiotemporal dynamics of the underlying cardiac sources remains to date unclear. in this paper, we derive a mathematical expression relating the spectrum of cardiac signals to the spatiotemporal dynamics of cardiac sources and the measurement characteristics of the lead systems. then, by using analytical methods and computer simulations we analyze the spectrum of cardiac signals measured by idealized lead systems during correlated and uncorrelated spatiotemporal dynamics. our results show that lead systems can have distorting effects on the spectral envelope of cardiac signals, which depend on the spatial resolution of the lead systems and on the degree of spatiotemporal correlation of the underlying cardiac sources. in addition to this, our results indicate that the spectral features that do not depend on the spectral envelope, such as the dominant frequency, behave robustly against different choices of lead systems.',\n",
       " 'relating the spectrum of cardiac signals to the spatiotemporal dynamics   of cardiac sources',\n",
       " 'the spectrum of cardiac signals in idealized lead systems')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 42\n",
    "arxiv_dataset[\"test\"][n][\"abstract\"], arxiv_dataset[\"test\"][n][\"title\"], generate(arxiv_dataset[\"test\"][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU-score\n",
    "\n",
    "Самоделки:\n",
    "- 0.02457 (словарь 6152, по 5 эпох по 5r-4, 1e-3, min.val.loss = 3.875) \n",
    "- **0.19204** (словарь 60 тыс. ~15 эпох с шагом 5e-4 -> 5e-5, min.val.loss = 2.289)\n",
    "- 0.12601 (словарь 84 тыс. много разных эпох, сходится плохо, min.val.loss = 3.305)\n",
    "- 0.10644 (BPE, словарь 16 тыс., много разных эпох, сходится плохо, min.val.loss = 3.8)\n",
    "\n",
    "T5-small\n",
    "- BLEU-score: **0.044...** 1% тюнинг\n",
    "- BLEU-score: **0.16563** (3 эпохи - 2,5 часа RTX2060 6Gb)\n",
    "\n",
    "T5-base\n",
    "- BLEU-score: **0.07422** (без обучения)\n",
    "- обучение не тянет...\n",
    "\n",
    "BART-base\n",
    "- BLEU-score: **0.17743** 1% тюнинг\n",
    "- BLEU-score: **0.17984** (1.43 эпохи - 2,5 часа RTX2060 6Gb)\n",
    "- BLEU-score: **0.19266** (2 эпохи)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2113/2113 [08:57<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-score: 0.19266\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "candidates = []\n",
    "references = []\n",
    "for example in tqdm(tokenized_arxiv[\"test\"]):\n",
    "    candidates.append(generate(example).split())\n",
    "    references.append([example[\"title\"].split()])\n",
    "\n",
    "score = bleu_score(candidates, references, max_n=3, weights=[1/3]*3)\n",
    "\n",
    "print('BLEU-score: {0:.5f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepik score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NAME = \"BART-base\" if USE_SMALL else \"BART-base-tune\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация заголовков для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:08<00:00,  4.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "abstracts = []\n",
    "titles = []\n",
    "\n",
    "for example in tqdm(scoring_dataset):\n",
    "    abstracts.append(example[\"abstract\"])\n",
    "    titles.append(generate(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, например"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The doc2vec approach was introduced as an extension to word2vec (Le and Mikolov, 2014), to generate embeddings at the level of entire documents, with interesting results, followed by mixed success at reproducing results from the initial paper. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and 2 advanced embedding-generating methodologies for documents. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models.',\n",
       " 'evaluation of the doc2vec embedding-generating methodologies')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[1], titles[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем полученные заголовки в файл формата `<abstract>,<title>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\n",
    "submission_df.to_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean     7.460000\n",
       "std      2.337919\n",
       "max     14.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[\"title\"].apply(lambda x: len(str(x).split())).describe()[[\"mean\",\"std\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью скрипта `generate_csv` приводим файл `submission_prediction.csv` в формат, необходимый для отправки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.create_submission import generate_csv\n",
    "\n",
    "generate_csv(input_file=f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\", \n",
    "             output_file=f'./submission/submission_{SUBMISSION_NAME}.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С учетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"./datasets/train.csv\")\n",
    "submission_df = pd.read_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}.csv\")\n",
    "\n",
    "intersect_idx = np.intersect1d(submission_df[\"abstract\"].str.lower(), train_df[\"abstract\"].str.lower(), return_indices=True)\n",
    "\n",
    "submission_df.loc[intersect_idx[1], 'title'] = train_df.loc[intersect_idx[2], 'title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.create_submission import generate_csv\n",
    "\n",
    "submission_df.to_csv(f\"./submission/predicted_titles_{SUBMISSION_NAME}_fake.csv\", index=False)\n",
    "\n",
    "generate_csv(input_file=f\"./submission/predicted_titles_{SUBMISSION_NAME}_fake.csv\", \n",
    "             output_file=f'./submission/submission_{SUBMISSION_NAME}_fake.csv', \n",
    "             voc_file=f'./datasets/vocs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./submission/submission_BART-base-tune_fake.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'./submission/submission_{SUBMISSION_NAME}_fake.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5-small:\n",
    "- **Score: 0.26174** 1% tuning\n",
    "- **Score: 0.34497** tuning 3 эпохи\n",
    "- **Score: 0.51810** + добавление правильных меток из трейна\n",
    "\n",
    "T5-base:\n",
    "- **Score: 0.20510** w/o tuning\n",
    "- для обучения с имеющейся длиной последовательности не хватает памяти GPU\n",
    "\n",
    "BART-base\n",
    "- **Score: 0.33851** 1% tuning\n",
    "- **Score: 0.39536** tuning 1,5 эпохи\n",
    "- **Score: 0.54804** + добавление правильных меток из трейна\n",
    "- **Score: 0.56782** + 2 эпохи с накоплением градиента (вот и в топ-10)\n",
    "- ... дальше не интересно"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d00ba0b92f737b23b3e678e3a3ceb3fe4e948ad1ab95d9c6fdcbb4b4ec65f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
