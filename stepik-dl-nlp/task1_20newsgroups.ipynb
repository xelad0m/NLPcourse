{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тематическая классификация длинных текстов - TFIDF и LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.265628Z",
     "start_time": "2019-09-12T12:42:55.188211Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlnlputils       # самописная библиотека от авторов курса\n",
    "from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, \\\n",
    "    vectorize_texts, SparseFeaturesDataset\n",
    "from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "\n",
    "init_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*) на видеокарте инициализация сидов не будет приводить к одинаковым результатам..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка текстов и подготовка признаков\n",
    "\n",
    "Примерно 18 тысяч текстов суммарно, из них примерно две трети содержатся в обучающей выборке, а треть в — тестовой.\n",
    "\n",
    "Длина текста — это несколько предложений плюс какая-то мета-информация. \n",
    "\n",
    "Классы в этом датасете обозначаются числами от 0 до 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.847399Z",
     "start_time": "2019-09-12T12:42:57.268037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих текстов 11314\n",
      "Количество тестовых текстов 7532\n",
      "\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "Метка 7\n"
     ]
    }
   ],
   "source": [
    "train_source = fetch_20newsgroups(subset='train')\n",
    "test_source = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print('Количество обучающих текстов', len(train_source['data']))\n",
    "print('Количество тестовых текстов', len(test_source['data']))\n",
    "print()\n",
    "print(train_source['data'][0].strip())\n",
    "\n",
    "print()\n",
    "print('Метка', train_source['target'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка \n",
    "\n",
    "В результате подготовки признаков мы получим две прямоугольные матрицы (из обучающей и тестовой выборок), строки которых соответствуют текстам, а столбцы — признакам.\n",
    "\n",
    "Первый шаг почти для всех задач обработки текстов — это **токенизация** — разбиение исходного текста на базовые лексические элементы, токены. Для этого используется простейшая самописная библиотека, где собраны несложные методы разбора текстов регулярками.\n",
    "\n",
    "После токенизации у нас остались только последовательности, состоящие из букв и цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:00.294422Z",
     "start_time": "2019-09-12T12:42:57.849386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from lerxst where thing subject what this nntp posting host rac3 organization university maryland college park lines wondering anyone there could enlighten this other door sports looked from late early called bricklin doors were really small addition front bumper separate from rest body this know anyone tellme model name engine specs years production where this made history whatever info have this funky looking please mail thanks brought your neighborhood lerxst\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = tokenize_corpus(train_source['data'])\n",
    "test_tokenized = tokenize_corpus(test_source['data'])\n",
    "\n",
    "print(' '.join(train_tokenized[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание словаря (отображение из строкового представления токена в его номер):\n",
    "- нумеруем все токены и затем в датасете строки заменяем на соответствующие им числа \n",
    "- для построения словаря мы используем только обучающую подвыборку\n",
    "- частоты мы будем хранить в словаре со значением по умолчанию\n",
    "- когда мы подсчитали частоты токенов, мы удаляем из словаря те токены, которые мы считаем неинформативными (слишком высоко- и низкочастотные по распределению Ципфа)\n",
    "- добавляем в список наших токенов фиктивный токен, причём добавляем его мы в начало. Мы делаем это для того, чтобы он получил идентификатор \"0\"\n",
    "\n",
    "С учётом фильтрации по частоте у нас получилось примерно 20 тысяч уникальных токенов — это достаточно много, на самом деле, для такого датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:00.825372Z",
     "start_time": "2019-09-12T12:43:00.297392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 21628\n",
      "[('that', 0), ('this', 1), ('have', 2), ('with', 3), ('writes', 4), ('article', 5), ('posting', 6), ('host', 7), ('nntp', 8), ('there', 9)]\n"
     ]
    }
   ],
   "source": [
    "MAX_DF = 0.8        # токены, имеющиеся в >80% документов не нужны\n",
    "MIN_COUNT = 5       # токеты, встретившиеся 5 и менее раз не нужны\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме словаря наша функция `build_vocabulary` возвращает ещё вектор весов — \"word_to_frequency\". Этот вектор содержит относительные частоты всех токенов в нашем датасете. Этот вектор нам понадобится на этапе формирования матрицы признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:01.524600Z",
     "start_time": "2019-09-12T12:43:00.829107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет мы токенизировали, словарь построили, можно перейти и к построению матрицы признаков. Для построения матрицы признаков по методу мешка слов мы будем использовать нашу функцию `vectorize_texts`:\n",
    "\n",
    "- строим прямоугольную матрицу, в которой количество строк соответствует количеству текстов, а количество столбцов соответствует количеству уникальных токенов (счётчики: сколько каждый токен встретился в каждом документе)\n",
    "- матрица счётчиков будет крайне разреженная (можем использовать разреженные матрицы из библиотеки scipy)\n",
    "- реализуем процедуру взвешивания. По умолчанию, в этой функции реализовано 4 алгоритма взвешивания (`{'tfidf', 'idf', 'tf', 'bin'}`)\n",
    "- используем мин-макс-стандартизацию*\n",
    "- переводим нашу разреженную матрицу в формат, ориентированный на эффективную работу со строками ([CSR, Compressed Sparse Row matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)), потому, что алгоритмы машинного обучения, которые мы далее будем использовать, читают документы один за другим и настраивают свои веса, то есть нам нужно уметь эффективно брать отдельный документ.\n",
    "\n",
    "\n",
    "\\*) Часто используется приведение к нормальному распределению с мат.ожиданием в нуле и единичной дисперсией. Но такой подход нам здесь не подходит... Потому что у нас матрица разреженная, и если мы сдвинем эту матрицу на её мат.ожидание, то мы получим не разреженную матрицу, и, скорее всего, она у нас для нормального датасета даже в память не влезет.\n",
    "\n",
    "**Для векторизации и обучающей, и тестовой выборки, используется один и тот же набор параметров, то есть один и тот же словарь, один и тот же вектор частот и один и тот же режим векторизации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorized_texts(name, *args, **kwargs):\n",
    "    path_to_obj = os.getcwd() + \"/data/\" + name + \"_20news_vectorized.pkl\"\n",
    "\n",
    "    if os.path.exists(path_to_obj):\n",
    "        with open(path_to_obj, 'rb') as fp:\n",
    "            return pickle.load(fp)\n",
    "    else:\n",
    "        result = vectorize_texts(*args, **kwargs)\n",
    "        with open(path_to_obj, 'wb') as fp:\n",
    "            pickle.dump(result, fp)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.094816Z",
     "start_time": "2019-09-12T12:43:01.526554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы признаков обучающей выборки (11314, 21628)\n",
      "Размерность матрицы признаков тестовой выборки (7532, 21628)\n",
      "\n",
      "Количество ненулевых элементов в обучающей выборке 1126792\n",
      "Процент заполненности матрицы признаков 0.46%\n",
      "\n",
      "Количество ненулевых элементов в тестовой выборке 721529\n",
      "Процент заполненности матрицы признаков 0.44%\n"
     ]
    }
   ],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "train_vectors = get_vectorized_texts(\"train\", train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "test_vectors = get_vectorized_texts(\"test\", test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print('Размерность матрицы признаков тестовой выборки', test_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()\n",
    "print('Количество ненулевых элементов в тестовой выборке', test_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.857114Z",
     "start_time": "2019-09-12T12:44:16.098773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_vectors.data, bins=20)\n",
    "plt.title('Распределение весов признаков')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение классов\n",
    "\n",
    "У нас всего 20 классов — классы распределены практически равномерно в обучающей выборке (мы можем смело использовать accuracy (или долю правильных предсказаний) как рабочую метрику). Если бы распределение классов было скошенным, эта метрика было бы уже неподходящей, она бы давала сильно завышенные оценки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.864960Z",
     "start_time": "2019-09-12T12:44:16.859476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных меток 20\n"
     ]
    }
   ],
   "source": [
    "UNIQUE_LABELS_N = len(set(train_source['target']))\n",
    "print('Количество уникальных меток', UNIQUE_LABELS_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.106036Z",
     "start_time": "2019-09-12T12:44:16.867310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_source['target'], bins=np.arange(0, 21))\n",
    "plt.title('Распределение меток в обучающей выборке');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.312198Z",
     "start_time": "2019-09-12T12:44:17.109884Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_source['target'], bins=np.arange(0, 21))\n",
    "plt.title('Распределение меток в тестовой выборке');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataset\n",
    "\n",
    "Обернём наши матрицы признаков в \"Dataset\" — это специальная идиома в pytorch, которая призвана повысить удобство подключения различных датасетов, которые могут подгружаться с жёсткого диска, из памяти; загружаться сразу все — в память, или читаться по чуть-чуть... \n",
    "\n",
    "Особенность в том, что \"features\" — это разреженная матрица, а `pytorch` НЕ умеет работать с разреженными матрицами\n",
    "\n",
    "Здесь мы используем `SparseFeaturesDataset`. Он описан в наши библиотечке - это очень простой класс, который принимает на вход в конструктор две матрицы — это матрица признаков, которая разрежена, и матрица меток:\n",
    "\n",
    "- храним весь dataset в разреженном виде, но, когда нам нужно выбрать один пример из датасета, мы выбираем только его из разреженной матрицы, конвертируем в плотное представление и заворачиваем в `torch.Tensor` \n",
    "- аналогично поступаем и с метками\n",
    "- метод \"len\" должен возвращать длину датасета, то есть количество примеров в нём \n",
    "- метод \"get item\" должен возвращать один обучающий пример, то есть, в случае нашего семинара — это вектор признаков и метка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.319292Z",
     "start_time": "2019-09-12T12:44:17.315074Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n",
    "test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели на PyTorch\n",
    "\n",
    "Наша модель — это **логистическая регрессия** (т.е. линейная регрессия, выход который сжимается в диапазон от нуля до единицы с помощью логистической функции - сигмоиды). \n",
    "\n",
    "Т.о. сама модель состоит всего лишь из одного слоя — это линейный слой, у которого количество входов соответствует количеству уникальных токенов, то есть размеру словаря, и количество выходов соответствует количеству меток в датасете. \n",
    "\n",
    "Эту нашу модель мы обучаем с помощью САМОПИСНОЙ функции `train_eval_loop`, которая реализует цикл обучения нейросети. Это функция общего назначения, сюда можно подавать модели не только для классификации, не только текстов, в ней реализованы некоторые стандартные фишки, которые используются при обучении нейросетей.\n",
    "\n",
    "- принимает целую кучу параметров, но среди этих параметров есть четыре главных: \n",
    "    - экземпляр модели\n",
    "    - обучающий датасет\n",
    "    - валидационный датасет \n",
    "    - функция потерь\n",
    "\n",
    "Порядок работы `train_eval_loop`:\n",
    "\n",
    "- переносим нашу модель на то устройство, на котором мы будем производить вычисления (CPU / GPU) \n",
    "- создаём оптимизатор, то есть — говорим, как именно мы должны делать градиентный шаг на каждой итерации \n",
    "- опционально, настраиваем расписание изменения скорости обучения (переменный шаг градиентного спуска — это часто хорошая идея, которая приводит к получению лучших значений метрик и функции потерь) \n",
    "- берём Dataset-ы, которые умеют возвращать обучающий пример по индексу (как мы только что рассмотрели), и передаём эти \"Dataset\" в \"DataLoader\" — это объект из `pytorch`, который умеет в многопоточном режиме собирать батчи примеров (цель - всегда загружать видеокарты на 100%)\n",
    "- определяем набор переменных, которые позволят нам, в ходе обучения, выбрать лучшую модель \n",
    "    - процесс обучения — стохастический, и модель может как улучшаться в ходе обучения, так и ухудшаться, и не всегда нужно брать последнюю модель \n",
    "    - хорошая практика для выбора лучшей модели в процессе обучения заключается в том, чтобы иметь отложенную выборку, состоящую из некоторого количества примеров, не входящих в обучающих выборку. И, после некоторого количества шагов по обучающей выборке, оценивать качество модели на валидационной выборке (то есть на этой отложенной выборке) и сравнивать качество моделей именно по значениям метрик, вычисленных на отложенной выборке. \n",
    "\n",
    "- начинается цикл обучения - состоит из нескольких эпох*, включающих:\n",
    "- цикл, реализующий одну эпоху обучения \n",
    "    - заданное количество градиентных шагов по обучающей выборке, на каждом шаге мы берём батч примеров — DataLoader нам возвращает уже не отдельные примеры, а целые пачки примеров\n",
    "    - переменная \"batch_x\" — это прямоугольная матрица, в которой количество строк равно количеству примеров в батче, то есть размеру батча, а количество столбцов — это количество признаков\n",
    "    - копируем данные на то же, устройство на котором была и модель, выполняем прямой проход по модели, получаем предсказания\n",
    "    - находим значение критерия (то есть значение функции потерь)\n",
    "    - очищаем оценки градиента с предыдущего шага, находим новое значение градиентов, и делаем градиентный шаг\n",
    "    - запоминаем среднее значение функции потерь на эпохе. Это полезно для **мониторинга процесса обучения**\n",
    "    \n",
    "\\*) Эпоха, в данном случае, носит условный характер — это некоторое количество градиентных шагов. Не обязательно эпоха — это полный проход по датасету. Наша эпоха начинается с того, что мы переводим модель в режим обучения.\n",
    "\n",
    "*Geforce 760GTX (3 сек./эпоха) примерно в 4-5 раз быстрее CPU i5-4440 (14 сек./эпоха)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:22.371272Z",
     "start_time": "2019-09-12T12:44:17.322178Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Эпоха: 354 итераций, 3.79 сек\n",
      "Среднее значение функции потерь на обучении 2.2252567908858176\n",
      "Среднее значение функции потерь на валидации 2.113699447805599\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 354 итераций, 3.19 сек\n",
      "Среднее значение функции потерь на обучении 0.9165917320103295\n",
      "Среднее значение функции потерь на валидации 1.6821936944783744\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 354 итераций, 3.38 сек\n",
      "Среднее значение функции потерь на обучении 0.46601735728945437\n",
      "Среднее значение функции потерь на валидации 1.4643886998548346\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 354 итераций, 3.11 сек\n",
      "Среднее значение функции потерь на обучении 0.28363620691885383\n",
      "Среднее значение функции потерь на валидации 1.3450367127434681\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 354 итераций, 3.23 сек\n",
      "Среднее значение функции потерь на обучении 0.19072449459867963\n",
      "Среднее значение функции потерь на валидации 1.2602410271006115\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 354 итераций, 3.06 сек\n",
      "Среднее значение функции потерь на обучении 0.13643478652683355\n",
      "Среднее значение функции потерь на валидации 1.2005355231842751\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 354 итераций, 3.15 сек\n",
      "Среднее значение функции потерь на обучении 0.10175166213832333\n",
      "Среднее значение функции потерь на валидации 1.154382390491033\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 354 итераций, 2.95 сек\n",
      "Среднее значение функции потерь на обучении 0.07793643180870236\n",
      "Среднее значение функции потерь на валидации 1.1209708641646272\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 354 итераций, 2.94 сек\n",
      "Среднее значение функции потерь на обучении 0.06176978719583844\n",
      "Среднее значение функции потерь на валидации 1.0886679420531806\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 354 итераций, 2.89 сек\n",
      "Среднее значение функции потерь на обучении 0.049217752096806205\n",
      "Среднее значение функции потерь на валидации 1.0575781093310501\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 10\n",
      "Эпоха: 354 итераций, 2.87 сек\n",
      "Среднее значение функции потерь на обучении 0.040086780887854806\n",
      "Среднее значение функции потерь на валидации 1.0522272642386161\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 11\n",
      "Эпоха: 354 итераций, 2.84 сек\n",
      "Среднее значение функции потерь на обучении 0.033054498271585186\n",
      "Среднее значение функции потерь на валидации 1.0252127043776593\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 12\n",
      "Эпоха: 354 итераций, 2.83 сек\n",
      "Среднее значение функции потерь на обучении 0.027422093115431274\n",
      "Среднее значение функции потерь на валидации 1.0233973603127366\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 13\n",
      "Эпоха: 354 итераций, 2.87 сек\n",
      "Среднее значение функции потерь на обучении 0.02306580696370726\n",
      "Среднее значение функции потерь на валидации 1.0005421087903492\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 14\n",
      "Эпоха: 354 итераций, 2.92 сек\n",
      "Среднее значение функции потерь на обучении 0.019530132435272726\n",
      "Среднее значение функции потерь на валидации 0.9915608245942552\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 15\n",
      "Эпоха: 354 итераций, 2.86 сек\n",
      "Среднее значение функции потерь на обучении 0.016497745108922237\n",
      "Среднее значение функции потерь на валидации 0.9758768220574169\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 16\n",
      "Эпоха: 354 итераций, 2.83 сек\n",
      "Среднее значение функции потерь на обучении 0.013959736680996072\n",
      "Среднее значение функции потерь на валидации 0.9762127609071085\n",
      "\n",
      "Эпоха 17\n",
      "Эпоха: 354 итераций, 2.90 сек\n",
      "Среднее значение функции потерь на обучении 0.012367763126724121\n",
      "Среднее значение функции потерь на валидации 0.9614301899732169\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 18\n",
      "Эпоха: 354 итераций, 2.84 сек\n",
      "Среднее значение функции потерь на обучении 0.01055141772988047\n",
      "Среднее значение функции потерь на валидации 0.953693501272444\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 19\n",
      "Эпоха: 354 итераций, 2.88 сек\n",
      "Среднее значение функции потерь на обучении 0.009276748799303241\n",
      "Среднее значение функции потерь на валидации 0.9553875873907137\n",
      "\n",
      "Эпоха 20\n",
      "Эпоха: 354 итераций, 2.85 сек\n",
      "Среднее значение функции потерь на обучении 0.008060228267005818\n",
      "Среднее значение функции потерь на валидации 0.9670810795436471\n",
      "\n",
      "Эпоха 21\n",
      "Эпоха: 354 итераций, 2.86 сек\n",
      "Среднее значение функции потерь на обучении 0.007328638883891626\n",
      "Среднее значение функции потерь на валидации 0.9403597160668696\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 22\n",
      "Эпоха: 354 итераций, 2.88 сек\n",
      "Среднее значение функции потерь на обучении 0.006772735545156513\n",
      "Среднее значение функции потерь на валидации 0.9329077365287279\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 23\n",
      "Эпоха: 354 итераций, 2.86 сек\n",
      "Среднее значение функции потерь на обучении 0.005589817580569662\n",
      "Среднее значение функции потерь на валидации 0.9329817854499413\n",
      "\n",
      "Эпоха 24\n",
      "Эпоха: 354 итераций, 2.89 сек\n",
      "Среднее значение функции потерь на обучении 0.0052566111611010305\n",
      "Среднее значение функции потерь на валидации 0.9690112267005242\n",
      "\n",
      "Эпоха 25\n",
      "Эпоха: 354 итераций, 2.94 сек\n",
      "Среднее значение функции потерь на обучении 0.004769204510803371\n",
      "Среднее значение функции потерь на валидации 0.9437598108740176\n",
      "\n",
      "Эпоха 26\n",
      "Эпоха: 354 итераций, 2.91 сек\n",
      "Среднее значение функции потерь на обучении 0.004408715462994809\n",
      "Среднее значение функции потерь на валидации 0.9343394120618448\n",
      "\n",
      "Эпоха 27\n",
      "Эпоха: 354 итераций, 3.04 сек\n",
      "Среднее значение функции потерь на обучении 0.004121565064816541\n",
      "Среднее значение функции потерь на валидации 0.9609657656085693\n",
      "\n",
      "Эпоха 28\n",
      "Эпоха: 354 итераций, 3.23 сек\n",
      "Среднее значение функции потерь на обучении 0.0041649071825273585\n",
      "Среднее значение функции потерь на валидации 0.9498733855405096\n",
      "Epoch    29: reducing learning rate of group 0 to 5.0000e-02.\n",
      "\n",
      "Эпоха 29\n",
      "Эпоха: 354 итераций, 3.25 сек\n",
      "Среднее значение функции потерь на обучении 0.0032320495637819056\n",
      "Среднее значение функции потерь на валидации 0.9344273266398301\n",
      "\n",
      "Эпоха 30\n",
      "Эпоха: 354 итераций, 2.97 сек\n",
      "Среднее значение функции потерь на обучении 0.002957672628542503\n",
      "Среднее значение функции потерь на валидации 0.9425019538503582\n",
      "\n",
      "Эпоха 31\n",
      "Эпоха: 354 итераций, 3.28 сек\n",
      "Среднее значение функции потерь на обучении 0.0028751809854556326\n",
      "Среднее значение функции потерь на валидации 0.9348612670171059\n",
      "\n",
      "Эпоха 32\n",
      "Эпоха: 354 итераций, 3.26 сек\n",
      "Среднее значение функции потерь на обучении 0.002601808519102633\n",
      "Среднее значение функции потерь на валидации 0.9306303299332069\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 33\n",
      "Эпоха: 354 итераций, 3.25 сек\n",
      "Среднее значение функции потерь на обучении 0.002713249549059208\n",
      "Среднее значение функции потерь на валидации 0.9447256854530108\n",
      "\n",
      "Эпоха 34\n",
      "Эпоха: 354 итераций, 3.20 сек\n",
      "Среднее значение функции потерь на обучении 0.002534757855056922\n",
      "Среднее значение функции потерь на валидации 0.9425583542403528\n",
      "\n",
      "Эпоха 35\n",
      "Эпоха: 354 итераций, 3.22 сек\n",
      "Среднее значение функции потерь на обучении 0.002610650506067237\n",
      "Среднее значение функции потерь на валидации 0.9399352367904227\n",
      "\n",
      "Эпоха 36\n",
      "Эпоха: 354 итераций, 3.05 сек\n",
      "Среднее значение функции потерь на обучении 0.0024109303134958533\n",
      "Среднее значение функции потерь на валидации 0.9386613392981432\n",
      "\n",
      "Эпоха 37\n",
      "Эпоха: 354 итераций, 3.26 сек\n",
      "Среднее значение функции потерь на обучении 0.0023538259098994925\n",
      "Среднее значение функции потерь на валидации 0.9419014562489623\n",
      "\n",
      "Эпоха 38\n",
      "Эпоха: 354 итераций, 3.16 сек\n",
      "Среднее значение функции потерь на обучении 0.0023111243744441284\n",
      "Среднее значение функции потерь на валидации 0.9422714688767821\n",
      "Epoch    39: reducing learning rate of group 0 to 2.5000e-02.\n",
      "\n",
      "Эпоха 39\n",
      "Эпоха: 354 итераций, 3.09 сек\n",
      "Среднее значение функции потерь на обучении 0.0019421875612901677\n",
      "Среднее значение функции потерь на валидации 0.9435697473206762\n",
      "\n",
      "Эпоха 40\n",
      "Эпоха: 354 итераций, 3.11 сек\n",
      "Среднее значение функции потерь на обучении 0.0018815696267013196\n",
      "Среднее значение функции потерь на валидации 0.9396212088354563\n",
      "\n",
      "Эпоха 41\n",
      "Эпоха: 354 итераций, 3.08 сек\n",
      "Среднее значение функции потерь на обучении 0.0018609639291393724\n",
      "Среднее значение функции потерь на валидации 0.9446353304941776\n",
      "\n",
      "Эпоха 42\n",
      "Эпоха: 354 итераций, 3.14 сек\n",
      "Среднее значение функции потерь на обучении 0.0018222656524884855\n",
      "Среднее значение функции потерь на валидации 0.9422192992800373\n",
      "\n",
      "Эпоха 43\n",
      "Эпоха: 354 итераций, 3.06 сек\n",
      "Среднее значение функции потерь на обучении 0.001788782024487069\n",
      "Среднее значение функции потерь на валидации 0.9431632204075991\n",
      "Модель не улучшилась за последние 10 эпох, прекращаем обучение\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n",
    "\n",
    "scheduler = lambda optim: \\\n",
    "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "best_val_loss, best_model = train_eval_loop(model=model,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            val_dataset=test_dataset,\n",
    "                                            criterion=F.cross_entropy,\n",
    "                                            lr=1e-1,\n",
    "                                            epoch_n=200,\n",
    "                                            batch_size=32,\n",
    "                                            l2_reg_alpha=0,\n",
    "                                            lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По **характеру изменения функции потерь** от эпохи к эпохе мы иногда можем понять, что не так с процессом обучения, мы можем увидеть, что модель вообще не сходится или — она очень быстро достигает определённой точки и дальше не учится, или значение функции потерь изменяется практически случайно, с большой дисперсией. Это важный диагностический показатель, поэтому мы выводим резюме по каждой эпохе. \n",
    "\n",
    "Для этого в той же самописной `train_eval_loop`:\n",
    "1. переводим модель в режим \"eval\" (то есть, в режим предсказания) и объявляем переменные для оценки среднего значения функции потерь на отложенной выборке\n",
    "2. повторяем практически те же самые действия, что и делали при обучении, но не делаем сам градиентный шаг — мы только получаем предсказание модели и оцениваем значение функции потерь\n",
    "    - важный момент, который позволит сэкономить память на видеокарте — это включить режим \"torch no_grad\". Когда этот режим включён, pytorch не сохраняет промежуточные данные, необходимые для вычисления градиентов\n",
    "3. сравниваем среднее значение функции потерь на валидации на последней эпохе и лучшее значение функции потерь, полученное аналогичным образом на предыдущих эпохах, и если новое среднее значение функции потерь — лучше, то мы сохраняем текущий вариант модели\n",
    "    - делаем это с помощью стандартной функции `copy.deepcopy()`\n",
    "    - если улучшить значение функции потерь на отложенной выборке после этой эпохи не получилось, то мы проверяем — а как давно у нас вообще получалось улучшить модель, если давно (по умолчанию 10 эпох) - то конец обучения\n",
    "    - если пользователь задал расписание изменения скорости обучения, то мы обновляем скорость обучения с учётом нового значения функции потерь\n",
    "\n",
    "Тело этого цикла мы обернули в `try-except` и добавили обработку двух видов исключений. Первое — это \"interrupt\", то есть — чтобы пользователь мог досрочно остановить обучение, нажав \"Ctrl-C\" в Jupyter ноутбуке. И второй обработчик ловит вообще все исключения и печатает их в удобоваримой виде.\n",
    "\n",
    "**Return**\n",
    "\n",
    "`train_eval_loop` возвращает 2 объекта:\n",
    "- лучшее значение функции потерь \n",
    "- модель с лучшими весами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные детали реализации основного цикла обучения:\n",
    "\n",
    "1. Изменение шага градиентного спуска:\n",
    "    - менять длину градиентного шага (увеличить) тогда, когда в течение пяти эпох значение функции потерь на валидации не улучшилось\n",
    "2. Функцию потерь мы используем CrossEntropy из pytorch\n",
    "    - позволяет нам убрать сигмоиду из самой модели и сделать процесс вычислений чуть более численно стабильным, то есть избежать слишком больших чисел или слишком маленьких. Это должно положительно сказаться на точности вычислений. *В данном конкретном случае это не требуется, просто хорошая практика*\n",
    "\n",
    "3. Вычисления ограничены: 200 проходов по датасету, то есть 200 эпох, размер батча 32\n",
    "    - на 28 и 38 эпохах уменьшается шаг обучения\n",
    "    - на 43 эпохе пришли к тому, что 10 последних эпох изменение функции потерь меньше порога и обучения закончено.\n",
    "    - данные цифры варьируются в небольших пределах в зависимости от сидов (+/-5-10 эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества\n",
    "\n",
    "Для удобства написали специальную функцию `predict_with_model`:\n",
    "\n",
    "- принимает на вход модель, датасет, идентификатор устройства (на котором необходимо производить вычисления), размер батча\n",
    "- в цикле, идёт по этому датасету, применяет модель и сохраняет результаты в список, а потом этот список преобразовывает в матрицу\n",
    "- на выходе у нас получается матрица, в которой количество строк соответствует количеству элементов в нашем датасете (количеству примеров в нашем датасете), а количество столбцов соответствует количеству классов\n",
    "- вычисляем значение функции потерь на обучающей выборке, а также оцениваем \"accuracy\", то есть долю верных ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:25.105663Z",
     "start_time": "2019-09-12T12:46:22.373012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/353.5625 [00:02<00:00, 123.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 0.0022322197910398245\n",
      "Доля верных ответов 0.9994696835778681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [00:01, 124.94it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 0.9289424419403076\n",
      "Доля верных ответов 0.76805629314923\n"
     ]
    }
   ],
   "source": [
    "train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "                             torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "                            torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что мы видим** \n",
    "\n",
    "\n",
    "- Модель очень хорошо работает на обучающей выборке и гораздо хуже - на валидационной.\n",
    "- Модель выделила случайные закономерности, не существующие в процессах реального мира, породивших обучающую выборку.\n",
    "\n",
    "Обучающую выборку модель практически запомнила — она идеально работает на обучающей выборке. Но на валидационной выборке она даёт верные ответы только в 77% случаев. Значение функции потерь на обучении — порядка нескольких тысячных, а на валидации — почти 1, то есть, значение функции потерь на валидации на два порядка больше, чем значение функции потерь на обучении. Это верный сигнал к тому, что наша модель **переобучилась**. Но даже, несмотря на такое сильное переобучение, в целом, доля верных ответов не такая плохая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Альтернативная реализация на scikit-learn\n",
    "\n",
    "Все вышеприведенное реализуется сайкит-слёрмом в 5 строчек.\n",
    "\n",
    "- задаём параметры алгоритма векторизации текстов\n",
    "- указываем токенизатор\n",
    "- задаём те же параметры для фильтрации токенов по частоте\n",
    "- говорим, что мы будем использовать логистическую регрессию \n",
    "- обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:31.791405Z",
     "start_time": "2019-09-12T12:46:25.107897Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_pipeline = Pipeline((('vect', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n",
    "                                                      max_df=MAX_DF,\n",
    "                                                      min_df=MIN_COUNT)),\n",
    "                             ('cls', LogisticRegression())))\n",
    "sklearn_pipeline.fit(train_source['data'], train_source['target']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:35.454567Z",
     "start_time": "2019-09-12T12:46:31.792832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 2.4954788918582493\n",
      "Доля верных ответов 0.9716280714159449\n",
      "\n",
      "Среднее значение функции потерь на валидации 2.6539022582340466\n",
      "Доля верных ответов 0.8190387679235263\n"
     ]
    }
   ],
   "source": [
    "sklearn_train_pred = sklearn_pipeline.predict_proba(train_source['data'])\n",
    "sklearn_train_loss = F.cross_entropy(torch.from_numpy(sklearn_train_pred),\n",
    "                                                 torch.from_numpy(train_source['target']))\n",
    "print('Среднее значение функции потерь на обучении', float(sklearn_train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], sklearn_train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "sklearn_test_pred = sklearn_pipeline.predict_proba(test_source['data'])\n",
    "sklearn_test_loss = F.cross_entropy(torch.from_numpy(sklearn_test_pred),\n",
    "                                                torch.from_numpy(test_source['target']))\n",
    "print('Среднее значение функции потерь на валидации', float(sklearn_test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], sklearn_test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Доля верных ответов на обучающей выборке — поменьше, то есть наша реализация давала accuracy 0.99, реализация scikit-learn даёт 0.96\n",
    "- На валидации, реализация scikit-learn работает лучше на 4%\n",
    "- Об этом же говорит и гораздо меньший разброс значения функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "- познакомились с одной из самых базовых моделей текста — **методом мешка слов**, а также, с одной из базовых моделей машинного обучения — **логистической регрессией**\n",
    "\n",
    "- рассмотрели все этапы подготовки текстов для того, чтобы подавать их в **нейросети**\n",
    "\n",
    "- рассмотрели некоторые универсальные компоненты, которые можно использовать для разных задач — не только для тематической классификации и даже не только для текстов:\n",
    "\n",
    "    - токенизацию, \n",
    "    - построение словаря, \n",
    "    - фильтрацию словаря, \n",
    "    - построение матрицы, \n",
    "    - использование pytorch Dataset, \n",
    "    - основной цикл обучения и валидации, \n",
    "    - выбор лучшей модели в процессе обучения, \n",
    "    - оценку качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# До.за.\n",
    "\n",
    "Предлагаем Вам поэкспериментировать с кодом этого семинара, чтобы попробовать улучшить качество на отложенной выборке. Что можно попробовать сделать:\n",
    "\n",
    "    - изменить способ взвешивания признаков\n",
    "    - реализовать взвешивание признаков с помощью точечной взаимной информации (PMI)\n",
    "    - изменить способ стандартизации данных (см. начиная с 4:25 на шаге 6), например, запоминая сдвиг и масштаб с обучающей выборки и применяя эти параметры для стандартизации тестовой выборки; и/или стандартизируя каждый столбец по отдельности\n",
    "    добавить регуляризацию\n",
    "    - извлекать признаки не через токены, а через N-граммы\n",
    "    - добавить стемминг или простую лемматизацию\n",
    "    - изменить архитектуру нейросети, например, сделав два слоя вместо одного\n",
    "    - проанализировать, как сильно падает качество классификации с уменьшением размера словаря (для фильтрации словаря можно использовать разные эвристики, например, тот же PMI)\n",
    "\n",
    "\n",
    "Подробно, как-нибудь потом, наверное. \n",
    "\n",
    "Подбор гиперпараметров по сетке - долго и скучно. Пока просто потыкаем имеющиеся опции по-отдельности по сравнению с базовым вариантом:\n",
    "\n",
    "- добавление L2-регуляризации с любой значимой величиной лямбды (>0.0001):\n",
    "    -  застревание в бесполезном локальном минимуме - точность **0,05** (лажа)\n",
    "- уменьшение объема подвыборки (`batch_size`):\n",
    "    - точность 0,76 (почти не меняется)\n",
    "- тип векторизации (отображения слов в вещественные вектора):\n",
    "    - `idf` - точность 0,75 (-1%)\n",
    "    - `tf` - точность 0,81 (+5%)\n",
    "    - `bin` - точность 0.72 (-4%)\n",
    "- масштабирование признаков:\n",
    "    - отключили - точность 0.66 (-10%)\n",
    "- токенизация:\n",
    "    - исключили менее редкие и более частотные токены - сузили словарь почти в 2 раза (21тыс. -> 12тыс.) - точность 0.78 (+2%)\n",
    "\n",
    "Лучшие вместе:\n",
    "- еще сильнее сузили словарь (до 9,5 тыс. слов)\n",
    "- векторизация токенов `tf`\n",
    "\n",
    "**0,79 (+3%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 9497\n",
      "[('that', 0), ('this', 1), ('have', 2), ('with', 3), ('writes', 4), ('article', 5), ('posting', 6), ('host', 7), ('nntp', 8), ('there', 9)]\n"
     ]
    }
   ],
   "source": [
    "MAX_DF = 0.75       # токены, имеющиеся в >75% документов не нужны\n",
    "MIN_COUNT = 15      # токены, встретившиеся 10 и менее раз не нужны\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORIZATION_MODE = 'tf'        # {'tfidf', 'idf', 'tf', 'bin'}\n",
    "train_vectors = get_vectorized_texts(\"train2\", train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE, scale=True)\n",
    "test_vectors = get_vectorized_texts(\"test2\", test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE, scale=True)\n",
    "\n",
    "train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n",
    "test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Эпоха: 354 итераций, 2.87 сек\n",
      "Среднее значение функции потерь на обучении 1.0285664128381653\n",
      "Среднее значение функции потерь на валидации 1.0335667519751242\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 354 итераций, 2.84 сек\n",
      "Среднее значение функции потерь на обучении 0.16352276093626428\n",
      "Среднее значение функции потерь на валидации 0.8858465251781172\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 354 итераций, 2.94 сек\n",
      "Среднее значение функции потерь на обучении 0.06637607571684707\n",
      "Среднее значение функции потерь на валидации 0.8403291975037527\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 354 итераций, 3.07 сек\n",
      "Среднее значение функции потерь на обучении 0.0368096472058803\n",
      "Среднее значение функции потерь на валидации 0.8068118878340317\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 354 итераций, 2.72 сек\n",
      "Среднее значение функции потерь на обучении 0.02524110681961401\n",
      "Среднее значение функции потерь на валидации 0.7851940952872826\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 354 итераций, 3.01 сек\n",
      "Среднее значение функции потерь на обучении 0.018184219634339298\n",
      "Среднее значение функции потерь на валидации 0.7737967207775278\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 354 итераций, 2.81 сек\n",
      "Среднее значение функции потерь на обучении 0.013836085068924869\n",
      "Среднее значение функции потерь на валидации 0.7707274246771457\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 354 итераций, 2.76 сек\n",
      "Среднее значение функции потерь на обучении 0.01158452840879728\n",
      "Среднее значение функции потерь на валидации 0.7564980599839809\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 354 итераций, 2.75 сек\n",
      "Среднее значение функции потерь на обучении 0.009705640824174898\n",
      "Среднее значение функции потерь на валидации 0.7557246725438005\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 354 итераций, 2.78 сек\n",
      "Среднее значение функции потерь на обучении 0.008006792084056105\n",
      "Среднее значение функции потерь на валидации 0.7627309747671677\n",
      "\n",
      "Эпоха 10\n",
      "Эпоха: 354 итераций, 2.80 сек\n",
      "Среднее значение функции потерь на обучении 0.007199045983643013\n",
      "Среднее значение функции потерь на валидации 0.7553496241443238\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 11\n",
      "Эпоха: 354 итераций, 2.77 сек\n",
      "Среднее значение функции потерь на обучении 0.00674729150822544\n",
      "Среднее значение функции потерь на валидации 0.7536700602810261\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 12\n",
      "Эпоха: 354 итераций, 2.83 сек\n",
      "Среднее значение функции потерь на обучении 0.005146661591466179\n",
      "Среднее значение функции потерь на валидации 0.7620817599028854\n",
      "\n",
      "Эпоха 13\n",
      "Эпоха: 354 итераций, 2.81 сек\n",
      "Среднее значение функции потерь на обучении 0.005216624212877477\n",
      "Среднее значение функции потерь на валидации 0.778899110474829\n",
      "\n",
      "Эпоха 14\n",
      "Эпоха: 354 итераций, 2.79 сек\n",
      "Среднее значение функции потерь на обучении 0.004941274974650393\n",
      "Среднее значение функции потерь на валидации 0.7580741076903829\n",
      "\n",
      "Эпоха 15\n",
      "Эпоха: 354 итераций, 2.79 сек\n",
      "Среднее значение функции потерь на обучении 0.005152250058839813\n",
      "Среднее значение функции потерь на валидации 0.7787272203397952\n",
      "\n",
      "Эпоха 16\n",
      "Эпоха: 354 итераций, 2.77 сек\n",
      "Среднее значение функции потерь на обучении 0.00361867104857597\n",
      "Среднее значение функции потерь на валидации 0.8039913684508558\n",
      "\n",
      "Эпоха 17\n",
      "Эпоха: 354 итераций, 2.76 сек\n",
      "Среднее значение функции потерь на обучении 0.003996672386160163\n",
      "Среднее значение функции потерь на валидации 0.7895796547122931\n",
      "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
      "\n",
      "Эпоха 18\n",
      "Эпоха: 354 итераций, 2.76 сек\n",
      "Среднее значение функции потерь на обучении 0.003014268353252572\n",
      "Среднее значение функции потерь на валидации 0.7634335905944897\n",
      "\n",
      "Эпоха 19\n",
      "Эпоха: 354 итераций, 2.82 сек\n",
      "Среднее значение функции потерь на обучении 0.00207442205233531\n",
      "Среднее значение функции потерь на валидации 0.7634712529005641\n",
      "\n",
      "Эпоха 20\n",
      "Эпоха: 354 итераций, 2.77 сек\n",
      "Среднее значение функции потерь на обучении 0.0023288605554656803\n",
      "Среднее значение функции потерь на валидации 0.7783406739896637\n",
      "\n",
      "Эпоха 21\n",
      "Эпоха: 354 итераций, 2.76 сек\n",
      "Среднее значение функции потерь на обучении 0.0020043157737591635\n",
      "Среднее значение функции потерь на валидации 0.7627703686386852\n",
      "\n",
      "Эпоха 22\n",
      "Эпоха: 354 итераций, 2.80 сек\n",
      "Среднее значение функции потерь на обучении 0.002039788273757713\n",
      "Среднее значение функции потерь на валидации 0.7850575347320509\n",
      "Модель не улучшилась за последние 10 эпох, прекращаем обучение\n"
     ]
    }
   ],
   "source": [
    "model_plus = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n",
    "\n",
    "scheduler = lambda optim: \\\n",
    "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "best_val_loss, best_model = train_eval_loop(model=model_plus,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            val_dataset=test_dataset,\n",
    "                                            criterion=F.cross_entropy,\n",
    "                                            lr=1e-1,\n",
    "                                            epoch_n=200,\n",
    "                                            batch_size=32,\n",
    "                                            l2_reg_alpha=0,\n",
    "                                            lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/353.5625 [00:02<00:00, 150.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 0.00460641598328948\n",
      "Доля верных ответов 0.9993812975075128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [00:01, 151.36it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 0.753052294254303\n",
      "Доля верных ответов 0.7900955921402018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "                             torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "                            torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
