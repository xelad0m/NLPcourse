{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание**<a id='toc0_'></a>    \n",
    "- [Основные виды нейросетевых моделей для обработки текстов](#toc1_)    \n",
    "    - [Виды и роли разлиных нейросетевых `модулей`](#toc1_1_1_)    \n",
    "- [Свёрточные нейросети](#toc2_)    \n",
    "      - [Пример](#toc2_1_1_1_)    \n",
    "      - [Применение свертки к тексту](#toc2_1_1_2_)    \n",
    "      - [Пример](#toc2_1_1_3_)    \n",
    "      - [Пример](#toc2_1_1_4_)    \n",
    "      - [Пример](#toc2_1_1_5_)    \n",
    "      - [Пример](#toc2_1_1_6_)    \n",
    "  - [Некоторые выводы](#toc2_2_)    \n",
    "      - [Пример](#toc2_2_1_1_)    \n",
    "      - [Пример](#toc2_2_1_2_)    \n",
    "- [Выводы](#toc3_)    \n",
    "  - [Выбор архитектуры нейронных сетей для задач NLP](#toc3_1_)    \n",
    "- [Теоретические вопросы: Свёрточные нейросети в обработке текста](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Основные виды нейросетевых моделей для обработки текстов](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cмысл использования нейросетей — в том, что они могут выделить сложные паттерны — взаимоотношения в данных. \n",
    "\n",
    "В случае текстов (а именно, отдельных предложений) такие паттерны проявляются в том, как именно слова употребляются вместе, как построены фразы. Другими словами, нейросети нужны для того, чтобы представить контекст в виде математического объекта — вектора или матрицы. \n",
    "\n",
    "Ранее мы уже говорили о первоначальном переводе текста в матрицу с помощью эмбеддингов и методов дистрибутивной семантики. \n",
    "\n",
    "Нейросети выполняют следующий шаг: \n",
    "- преобразование этой матрицы так, чтобы каждая строчка содержала информацию не об отдельных словах, а о фразах и их смыслах. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Виды и роли разлиных нейросетевых `модулей`](#toc0_)\n",
    "\n",
    "Задачи обработки текста являются комплексными и инструменты их решения подразделяются на крупные блоки методов из которых собирается \"конвеер\", решающий конкретную прикладную задачу.\n",
    "\n",
    "Такие блоки методов (модули) включают:\n",
    "\n",
    "- свёрточные блоки (convolutional NN, CNN)\n",
    "    - аналогичны работающим с изображениями (используются не двухмерные свёртки, а одномерные)\n",
    "    - выявляют паттерны вне зависимости от их позиции (инвариантность к переносу в пространстве)\n",
    "    - быстные, простые, хорошо обучаются (хорошо распрараллеливаются)\n",
    "    - могут быть недостаточно гибкими (не могут сравнивать информацию о словах в начале и конце предложения, увеличение размера изучаемого паттерна требует кратного увеличения количества параметров)\n",
    "\n",
    "- рекуррентные блоки (recurrent NN, RNN)\n",
    "    - лучше подходят к задачам обработки текста\n",
    "    - читаем слово за словом или символ за символом и на каждом шаге поддерживаем некоторый вектор:\n",
    "        - **вектор скрытого состояния**, который содержит информацию о всём тексте, который мы прочитали ранее\n",
    "    - может учитыват достаточно длинные зависимости\n",
    "    - длина учитываемых зависимостей не обязательно связана с количеством параметров сети\n",
    "    - учить рекуррентные сети гораздо сложнее.\n",
    "\n",
    "        *В целом нейросетевые блоки обеспечивают:*  \n",
    "        *- Учет сложного контекста слов*  \n",
    "        *- Улучшение качества решения задачи за счёт объединения нескольких шагов в одну архитектуру, обучаемую end-to-end *градиентным спуском*  \n",
    "        *- Анализ формулировок, структуры фраз*\n",
    "\n",
    "- блоки объединения (агрегации, [pooling](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer))\n",
    "    - аналогичные соответствующим методам обработки изображений (оставляют главное, убирают незначащие детали), в обработки изображений, например, усреднение матрицы изображений по соседним элементам и т.п.\n",
    "    - локальный пулинг - уменьшить длину, укрупнить детали\n",
    "    - глобальный пулинг - например, для задачи классификации текстов, по векторам токенов и т.п. получить вектор текста фиксированного размера\n",
    "\n",
    "- механизм внимания (attention mechanism, self-attention) - один из свежих подходов\n",
    "    - оказалось, что достаточно лишь одного \"внимания\" для решения почти всех задач обработки текстов\n",
    "    - учитывает сколь угодно далекие друг от друга зависимости\n",
    "    - умная агрегация\n",
    "    - сети с вниманием быстрые, хорошо обучается\n",
    "    - можно рассматривать механизм внимания как умный адаптивный пулинг\n",
    "\n",
    "- архитектуры с памятью (memory NN, neural Turing machines) - считается экзотикой\n",
    "    - обобщение рекуррентных нейросетей (в RNN один вектор в ячейке, здесь много таких векторов, и на каждом шаге мы можем выбрать)\n",
    "    - потенциально (теоретически) могут решать абсолютно любую задачу\n",
    "    - на практике медленно сходятся, полезная емкость памяти часто оказывается меньше чем ожидается\n",
    "  \n",
    "- рекрусивные сети (tree-recursive NN)\n",
    "    - еще одно обобщение RNN, но не путем добавлением памяти, а за счет использовая деревьев, а не последовательностей (токенов и т.п.)\n",
    "    - т.е. сначала строиться некоторое семантическое дерево, а потом из него, а не из текста набирается информация для нейросети\n",
    "    - полезно для языков со свободным порядком слов (в т.ч. русского)\n",
    "    - однако, на практике часто результативность не сильно лучше RNN\n",
    "\n",
    "- графовые сверточные нейросети (graph convolutionsl NN, GCNN)\n",
    "    - обобщение RNN+CNN на произвольную структуру графа\n",
    "        - в RNN в тексте в картинках токены/пикесели связаны только с соседями (одномерно, двухмерно), а тут некоторым образом строится граф связей элементов текста/картинки\n",
    "    - новое перспективное направлени\n",
    "    - высокая вычислительная сложность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Свёрточные нейросети](#toc0_)\n",
    "\n",
    "Cвёртка - операция, выполняемая над двумя функциями или сигналами, дающая некий третий сигнал. \n",
    "$$(f*g)(x) = \\int_{-\\infin}^{\\infin} f(x) g(x -y)dy$$\n",
    "$$ConvOut_i = \\sum_{k-1}^K InSignal_{i-\\frac{K}{2}+k} \\cdot Kernel_k, \\forall i \\in 0,1, ...L$$\n",
    "\n",
    "\n",
    "- первый сигнал ($f$) — это входные данные, \n",
    "- второй сигнал ($g$) — это bias, intercept (часть параметров нейросети, которые выполняют роль **ядра свёртки**)\n",
    "- перебираются все возможные смещения ядра относительно входящего сигнала\n",
    "- для каждого смещения измеряется сходство фрагмента сигнала с ядром\n",
    "    - скалярное произведение фрагмента сигнала с ядром свёртки для дискретного случая\n",
    "\n",
    "В дискретном случае:\n",
    "- результат применения одномерной свёртки — это вектор. \n",
    "    - допустим есть входной сигнал размера L+K-1. \n",
    "    - допустим ядро имеет размер K = 3\n",
    "    - проходя по сигналу окном размера K получим L значений скалярного произведения ядра и фрагментов сигнала\n",
    "- очевидно, что фиксированное ядро с одинаковыми фрагментами сигнала даст одинаковую свертку, независимо от расположения этого фрагмента в сигнале\n",
    "\n",
    "Это позволяет нам выделять локальные паттерны безотносительно их позиции в сигнале. А **ядро свёртки**, при этом, описывает паттерн, который мы ищем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_1_'></a>[Пример](#toc0_)\n",
    "\n",
    "Примените свёртку с ядром (-0.5, 0, 0.5) к сигналу (1, 1, 2, 3, 3, 3, 2, 1, 1). Ответ запишите в виде последовательности чисел, разделённых пробелами. В качестве десятичного разделителя используйте точку. Входную последовательность не нужно дополнять фиктивными элементами (padding выключен).\n",
    "\n",
    "Шаг свёртки (stride в PyTorch) считаем 1.\n",
    "\n",
    "    - сигнал симметричный\n",
    "    - свертка показала противоположные значения на зеркально симметричных фрагментах сигнала\n",
    "    - потомушта такое ядро специальное "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  1. ,  0.5,  0. , -0.5, -1. , -0.5])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view     # numpy>=1.20\n",
    "\n",
    "sig = np.array([1,1,2,3,3,3,2,1,1])\n",
    "ker = np.array([-0.5, 0, 0.5])\n",
    "fragments = sliding_window_view(sig, window_shape = ker.shape[0])\n",
    "fragments @ ker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5, -1. , -0.5,  0. ,  0.5,  1. ,  0.5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve(sig, ker, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5000,  1.0000,  0.5000,  0.0000, -0.5000, -1.0000, -0.5000]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# размерность тензора должна соответствовать явно: (1, 1, 3), а не (3, )\n",
    "# тип должен совпадать с типом в ядра, т.к. торч это Си\n",
    "input_1d = torch.tensor(sig.reshape(1,1,-1).astype('float'))    \n",
    "kernel = torch.tensor(ker.reshape(1,1,-1))\n",
    "\n",
    "nn.functional.conv1d(input_1d, kernel, padding=0)   # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_2_'></a>[Применение свертки к тексту](#toc0_)\n",
    "\n",
    "- строится матрица эмбеддингов (дистрибутивная семантика) (Количество токенов Х Длина эмбеддинга)\n",
    "- проходим по матрице окном размера $k$ (строк/эмбеддингов)\n",
    "- вытягиваем эти $k$ эмбеддингов в один вектор\n",
    "- вычисляем скалярное произведение с ядром (его размерность: Величина окна Х Длина эмбеддинга)\n",
    "    - тоже самое делается с другими ядрами (ядер будет много, каждое ищет свой паттерн)\n",
    "    - получаем вектор для окна размерности, равной количеству ядер\n",
    "- в итоге получили матрицу размерности ((Количество окон = Длина текста - Размер окна + 1) Х Количество ядер)\n",
    "\n",
    "- следующий возможный шаг - применение к этой матрице блока пулинга, который более активно, чем свертка, уменьшает число строк в матрице (усредняет соседние строки, или еще как то)\n",
    "\n",
    "    - Обычно свёрточные блоки применяют один за другим, перемешивая (это пока не очень понятно, походу имеется в виду, что просто в конвеер подключается пулинг) с блоками пулинга или агрегации, а также с функциями активации. Делают это для того, чтобы расширить пятно восприятия, то есть получить возможность обрабатывать более широкий контекст, более длинные паттерны: вектор, выходящий из пулинга уже зависит от большего числа входящих эмбеддингов (**рецептивное поле**, receptive field)\n",
    "\n",
    "**Вопрос:**\n",
    "\n",
    "В картиночных задачах каждый элемент входного вектора имеет интерпретацию, то можно сделать такие любопытные вещи как, обучить сеть, взять значение промежуточного слоя, использовав его как маску, наложить на входное изображение и получить области на исходном изображении, которые наиболее важны для нейронной сети, а можно ли как-то сделать тоже самое, но для задач НЛП?\n",
    "\n",
    "**Ответ:**\n",
    "\n",
    "В разных архитектурах для этого используются \"слои внимания\" (attention layers), и в современных архитектурах они позволяют не просто узнать, на что смотрела сеть (ради любопытства или оптимизации), но направить обработку следующих слоёв. То есть слой внимания вырабатывает дополнительный набор признаков, который конкатенируется или прямо домножается на векторное представление (слова, фразы, параграфа), по которому следующие слои учатся обрабатывать текст согласно заданию.\n",
    "\n",
    "**Воспрос:**\n",
    "\n",
    "Свертка в задачах НЛП не такая очевидная, как в картиночных задачах. Ведь в картиночных задачах каждый элемент вектора имеет физический смысл вида, яркости пикселя в RGB пространстве (или другом), а в задачах НЛП же, значение вектора это уже некоторая абстракция, которая напрямую никак не сопоставляется с каким-то словом или символом.\n",
    "\n",
    "**Ответ:**\n",
    "\n",
    "Промежуточное векторное описание до каких-то пор тоже не очень специфично отражает смысл слова. До тех пор, пока не появился word2vec и стало возможным составлять смысловые пропорции типа \"огурец минус зелёный плюс фиолетовый\"... Свёртка просто делает что-то с числами, векторным представлением слов/предложений/параграфов, и если представление построено согласно адекватной модели языка, состав масок свёртки может означать что-то интересное.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_3_'></a>[Пример](#toc0_)\n",
    "Оцените ширину рецептивного поля для нейросети, состоящей из 4 свёрточных слоёв с ядром 5, соединённых последовательно. Код на PyTorch для создания такой нейросети:\n",
    "\n",
    "    nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5),\n",
    "        nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5),\n",
    "        nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5),\n",
    "        nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5)\n",
    "    )\n",
    "\n",
    "Ширина рецептивного поля - наибольшее расстояние между элементами входной последовательности, которые могут влиять на один и тот же элемент выходной последовательности, плюс один.\n",
    "\n",
    "Например, ширина рецептивного поля для одного свёрточного блока с ядром 3 равна 3. Для двух таких блоков, соединённых последовательно - 5.\n",
    "\n",
    "На каждом шаге (сверточном слое) прибавляется справа и слева по половине окна без центра, плюс сам центр окна:\n",
    "\n",
    "$$rf_1 = k = 1 + \\frac{k-1}{2} \\cdot 2 \\cdot 1 \\\\\n",
    "rf_2 = 1 + \\frac{k-1}{2} \\cdot 2 \\cdot 2 \\\\\n",
    "rf_3 = 1 + \\frac{k-1}{2} \\cdot 2 \\cdot 3 \\\\\n",
    "... \\\\\n",
    "rf_n = 1 + (k-1) \\cdot n $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, n = 5, 4\n",
    "rf = 1 + (k-1)* n\n",
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_4_'></a>[Пример](#toc0_)\n",
    "\n",
    "**Примените свёртку к входной последовательности, в которой каждый элемент кодируется вектором размерности 2 (часть 1)**\n",
    "\n",
    "Рассмотрим многоканальную свертку, принимающую на вход матрицу $X^{InLen, InChannels}$, где $InLen$ - количество строк, равное длине входной последовательности, $InChannels$ - количество столбцов, равное количеству признаков для каждого элемента во входной последовательности.\n",
    "\n",
    "В результате получается матрица $Y^{OutLen}$, где $OutLen = InLen - K + 1$ - длина выходной последовательности, $K$ - размер ядра свёртки.\n",
    "\n",
    "Ядро свертки с одним выходным каналом задаётся двумерным тензором $Kernel^{InChannels, K}$.\n",
    "\n",
    "Многоканальная свёртка реализуется следующей формулой (аналогично одноканальной, но на выходной канал влияют все входные каналы):\n",
    "\n",
    "$$Y[pos] = Bias+ \\sum_{k=0}^{K-1} \\sum_{ic=0}^{InChannels - 1} X_{[pos + k,ic]} Kernel_{[ic,k]}$$\n",
    " \n",
    "Обратите внимание, что по аналогии с логистической регрессией, кроме ядра свёртки, есть ещё обучаемый параметр сдвига $Bias$.\n",
    "\n",
    "Рассмотрим конкретный пример:\n",
    "\n",
    "<img src=\"./img/convo1_color.png\" width=\"300\">\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Для входной последовательности:\n",
    "\n",
    "$$X^{5, 2} = \\left( \\begin{matrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ \\end{matrix} \\right)$$\n",
    "\n",
    "Ядра, заданного следующей матрицей и нулевого смещения:\n",
    "\n",
    "$$Kernel^{2, 3}= \\left( \\begin{matrix} 1 & 1 & 0\\\\ 0 & 1 & 1\\\\ \\end{matrix} \\right) , Bias=0$$\n",
    "\n",
    "Посчитайте выходной вектор Y:\n",
    "\n",
    "$$Y[pos] = Bias + \\sum_{k=0}^{2} \\sum_{ic=0}^{1} X_{[pos + k,ic]} Kernel_{[ic, k]}$$\n",
    "\n",
    "В ответ впишите содержимое вектора $Y$ , состоящего из трех чисел, числа разделяйте пробелами. В качестве разделителя дробной части используйте точку.\n",
    "\n",
    "Параметр сдвига считайте нулевым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view         # numpy>=1.20\n",
    "\n",
    "x = np.array([[1, 1, 0, 0, 1], \n",
    "              [0, 1, 0, 1, 0]]).T\n",
    "ker = np.array([[1, 1, 0], \n",
    "                [0, 1, 1]])\n",
    "b = 0\n",
    "\n",
    "windows = sliding_window_view(x, window_shape = ker.T.shape)    # лишнее измерение схлопнется в сумме\n",
    "masked = windows * ker.T\n",
    "b + np.sum(masked, axis=tuple(range(1, masked.ndim)))           # сумма по всем измерениям, кроме первого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "convolve2d(x.T, ker, mode='valid').squeeze()                    # в 3 раза шустрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_5_'></a>[Пример](#toc0_)\n",
    "**Примените свёртку к входной последовательности, в которой каждый элемент кодируется вектором размерности 2. (часть 2)**\n",
    "\n",
    "Усложним еще немного многоканальную свертку: теперь у нас будет несколько выходных каналов.\n",
    "\n",
    "По прежнему будем подавать на вход матрицу $X^{InLen, InChannels}$, где $InLen$ - количество строк, равное длине входной последовательности, $InChannels$ - количество столбцов, равное количеству признаков для каждого элемента во входной последовательности.\n",
    "\n",
    "Но на этот раз ядро многоканальной свёртки задается трёхмерным тензором $Kernel^{OutChannels, InChannels, K}$, где новым измерением будет $OutChannels$ - количество признаков для каждого элемента выходной последовательности.\n",
    "\n",
    "Тогда результатом применения свертки будет матрица $Y^{OutLen, OutChannels}$, где $OutLen = InLen - K + 1$ - длина выходной последовательности, $K$ - размер ядра свёртки, $OutChannels$ - количество признаков для каждого элемента выходной последовательности.\n",
    "\n",
    "Свёртка реализуется следующей формулой:\n",
    "\n",
    "$Y[pos,oc] = Bias[oc] + \\sum_{k=0}^{K-1} \\sum_{ic=0}^{InChannels - 1} X[pos + k,ic] Kernel[oc,ic,k]$\n",
    "\n",
    "Обратите внимание,  теперь параметр сдвига - это вектор обучаемых параметров $Bias^{OutChannels}$ \n",
    "\n",
    "Рассмотрим модифицированный пример из прошлого шага:\n",
    "\n",
    "<img src=\"./img/convo2_color.png\" width=\"300\">\n",
    "\n",
    "Входная последовательность:\n",
    "\n",
    "$$X^{5, 2} =\\left( \\begin{matrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ \\end{matrix} \\right)$$\n",
    "\n",
    "Ядро (каждая матрица соответствует срезу по первому измерению - $OutChannels$, - и имеет семантику $InChannels x KernelSize$:\n",
    "\n",
    "$$Kernel^{2,2, 3}=\\left( \\begin{matrix} 1 & 1 & 0\\\\ 0 & 1 & 1\\\\ \\end{matrix} \\right) \\left( \\begin{matrix} 1 & 0 & 0\\\\ 0 & 0 & 1\\\\ \\end{matrix} \\right)$$\n",
    "\n",
    "В ответ впишите содержимое матрицы, каждая строка матрицы на отдельной строке, числа разделять пробелами. В качестве разделителя дробной части использовать точку.\n",
    "\n",
    "Параметр сдвига считайте нулевым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 2],\n",
       "       [2, 2, 2],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 1, 0, 0, 1], \n",
    "              [0, 1, 0, 1, 0]])\n",
    "\n",
    "ker = np.array([[[1, 1, 0], \n",
    "                 [0, 1, 1]], \n",
    "                [[1, 0, 0], \n",
    "                 [0, 0, 1]],\n",
    "                [[1, 0, 0], \n",
    "                 [0, 1, 1]]])\n",
    "\n",
    "def convolve_Nto1(x, ker, b=0):\n",
    "    windows = sliding_window_view(x.T, window_shape = ker.T.shape)\n",
    "    masked = windows * ker.T\n",
    "    return b + np.sum(masked, axis=tuple(range(1, masked.ndim)))\n",
    "\n",
    "def convolve_NtoM(x, ker, b=0):\n",
    "    return np.array(list(map(lambda ker: convolve_Nto1(x, ker, b=b), ker))).T\n",
    "\n",
    "convolve_NtoM(x, ker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_6_'></a>[Пример](#toc0_)\n",
    "Оцените количество параметров в свёрточном блоке, принимающем 64 канала, возвращающем 128 каналов, длина ядра 5. Не забывайте про параметры сдвига (bias, их количество соответствует количеству выходных каналов).\n",
    "\n",
    "Че такое параметры? То что мы оцениваем в ходе вычисления блока:\n",
    "\n",
    "- Количество входных каналов Х Размер ядра Х Количество выходных каналов + Количество выходных каналов (смещения) = 41088\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[Некоторые выводы](#toc0_)\n",
    "\n",
    "- Как правило, свёрточные нейросети хорошо обучаются и сходятся. \n",
    "  - слабо выражена проблема **затухания градиента**\n",
    "- Такие архитектуры хорошо подходят для распознавания коротких локальных особенностей, например — словосочетаний или коротких фраз. \n",
    "- Заставить свёрточную нейросеть обрабатывать длинные предложения и учитывать широкий контекст достаточно сложно \n",
    "  - для этого необходимо сделать очень глубокую сеть, в которой неминуемо будет много параметров, что сильно усложнит процесс обучения\n",
    "  - максимальная ширина паттерна привязана к количеству параметров нейросети \n",
    "\n",
    "- Чтобы расширить пятно восприятия, можно применять \"разреженные свёртки\" (\"dilated convolutions\"). \n",
    "  - Идея в том, что ядро свёртки применяется не к непрерывному фрагменту сигнала, а к фрагменту, из которого удалена часть элементов (как правило, удаляют элементы с чётными номерами). Таким образом почти в два раза увеличивается рецептивное поле, а количество параметров остаётся прежним. \n",
    "  - Если применять разреженные свёртки на первом слое, мы, фактически, будем игнорировать каждое второе слово, это совсем не то что мы хотим. Поэтому на первом слое применяют обычные, не прореженные свёртки, а затем на каждом новом уровне увеличивают прореживания в два раза. Таким образом, мы можем сэкономить количество параметров, увеличив рецептивное поле. \n",
    "\n",
    "- применимы для задачи генерации текста\n",
    "  - для вычисления свёртки нам требуются элементы не только слева, но и справа. Для решения задачи генерации текста, берется только левая часть окна, по которму проходит ядро. Такой подход, кстати, называется **авторегрессией**.\n",
    "\n",
    "В свёрточных нейросетях проблема **затухания градиента** тоже есть. Однако она проявляется не с ростом длины входной последовательности, а с увеличением глубины (то есть количества слоёв). \n",
    "\n",
    "Самые распространённые методы борьбы с затуханием градиента - частично-линейные функции активации (например, LearkyReLU), блоки со связями в обход нелинейностей (skip connections, residual blocks), а также нормализация (например, BatchNorm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_1_'></a>[Пример](#toc0_)\n",
    "Вычислите, сколько потребуется свёрточных слоёв с непрореженными свёртками (dilation=1 в PyTorch) с ядром длины 5, чтобы учесть связь между первым словом в предложении и 30-м.\n",
    "\n",
    "$$ rf_n = 1 + (k-1) \\cdot n \\\\\n",
    "30 = 1 + (5 - 1) \\cdot n \\\\\n",
    "n = \\frac{30 - 1}{5 - 1} = 7.25 \\rightarrow 8$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_2_'></a>[Пример](#toc0_)\n",
    "\n",
    "Вычислите, сколько потребуется свёрточных слоёв с прореженными свёртками (dilation>1 в PyTorch) с ядром длины 5, чтобы учесть связь между первым словом в предложении и 30-м (при этом длина текста больше 30и слов!).\n",
    "\n",
    "Начинать принято с dilation=1 (непрореженные свёртки) и увеличивать на каждом шаге в 2 раза: $Dilation[layer]=2^{layer}$, layer - номер слоя, **начиная с 0**.\n",
    "\n",
    "$$ rf_n = 1 + (k-1) \\cdot 2^{n}\\\\\n",
    "30 = 1 + (5 - 1) \\cdot 2^n\\\\\n",
    "2^n = \\frac{30 - 1}{5 - 1} = 7.25\\\\\n",
    "\\ln 2^{n} = \\ln 7.25 = 1.981...\\\\\n",
    "n = 2.85...\\\\\n",
    "n = 3$$\n",
    "\n",
    "Но тут n это номер слоя, начиная с 0, поэтому количество слоев 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 9, 17, 33, 65], 2.8579809951275723)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = lambda n: 1 + (k - 1) * 2 ** n\n",
    "list(map(rf, range(5))), np.log(7.25) / np.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая формула количества слов на выходе слоя от количества слов на входе:\n",
    "\n",
    "$$W_{out} = \\left \\lfloor \\frac{W_{in} + 2 \\times padding - dilation \\times (ker\\_size - 1)}{stride} + 1 \\right \\rfloor$$\n",
    "\n",
    "    padding - добавление справа и слева фиктивных слова\n",
    "    dilation - прореживание (сколько пропускается)\n",
    "    ker_size - размер ядра свёртки\n",
    "    stride - шаг свертки\n",
    "Смысл этих параметров хорошо показан [тут](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)\n",
    "\n",
    "1. Формула используется для согласованого выбора параметров свертки под нужные значения количества вх./вых. каналов\n",
    "2. Для многомерной (многоканальной) свертки также верна, с учетом того, что по каждому $i$-му измерению будут свои количества входов/выходов, и выбираются свои $padding_i$, $dilation_i$, $ker\\_size_i$, $stride_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Выводы](#toc0_)\n",
    "1. Одна из проблем свёрток заключается в том, что максимальная ширина паттерна привязана к количеству параметров нейросети. Это не очень удобно. \n",
    "2. Увеличить рецептивное поле можно с помощью блоков агрегации или пулинга, а также с помощью прореживания. \n",
    "3. Авторегрессионные модели — это что-то среднее между свёрточными и рекуррентными нейросетями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Выбор архитектуры нейронных сетей для задач NLP](#toc0_)\n",
    "\n",
    "Как обычно **на практике** подходят к решению задач с помощью нейронный сетей те, кто этим реально занимается (Роман Суворов, автор курса):\n",
    "\n",
    "1. Если для этой задачи уже кто-то что то применял, надо взять основные идеи (принять за **baseline**). Читать статьи и чужой код в поисках идей.\n",
    "2. Постараться выяснить, **какие особенности языка могут отвечать за решение задачи** (это отдельные фразы или лексический состав в целом или что-то ещё, насколько далёкие связи нужно уметь улавливать). Нужно постараться заложить своё понимание механизма (как это происходит в реальном мире) в архитектуру (модель реального мира). Например, если целевые метки сильно коррелируют с общим составом словаря, не нужно пытаться городить свёртки с большим receptive field, и вообще не надо сильно усложнять архитектуру - линейная модель + fasttext должны зарешать (если речь о классификации). Наоборот, если важен контекст, нужно постараться максимально быстро вырастить рецептивное поле за наименьшее число слоёв. Закладывание знаний и ограничений в модель ещё называется inductive bias - модели будет проще обобщиться, если данных не сильно много.\n",
    "3. Когда сделал вариант архитектуры, добиться, чтобы она начала переобучаться на ограниченном количестве данных (например, на одном батче). Когда она сможет переобучиться - значит при большем количестве данных она сможет и обобщиться. **Если модель не переобучается на одном батче, значит она вообще не учится.**\n",
    "4. Сравнивать **train loss и validation loss** - если на трейне лосс сильно меньше, то мы переобучаемся, надо облегчать модель (добавить дропаута, уменьшить количество каналов в свёртках, добавить аугметаций). Если на трейне и валидации лосс одинаковый, то мы недообучаемся, надо усилить модель. Если на валидации лосс сильно меньше, то скорее всего валидационный датасет либо проще, либо валидация вообще нерепрезентативная - надо внимательно на неё посмотреть - чудес не бывает. Если датасет маленький, важно использовать кросс-валидацию или усреднение по нескольким случайным разбивкам на трейн и тест.\n",
    "5. Если хочешь **увеличить количество слоёв**, используй residual connections (в курсе они ещё называются \"связи в обход нелинейностей\") - это сильно упрощает сходимость.\n",
    "6. **Cвёрточные НН** проще заставить работать, чем рекуррентки, поэтому лучше начинать с них.\n",
    "7. Можно **комбинировать** разные виды архитектур - сначала сделать несколько слоёв свёрток, потом добавить рекуррентку, сверху добавить, например, условные случайные поля (CRF), если задача типа NER, Named-entity recognition (выделить спаны сущностей (персоны, локации, даты и т.п) в тексте).\n",
    "8. Сначала стоит **добиваться наилучшего качества** любыми средствами - прикручивая сколь угодно тяжелые модели, берты, трансформеры и т.п. Когда качество устраивает - можно переключиться на сжатие полученной модели.\n",
    "9. Смотреть глазами на ошибки, **генерировать гипотезы** насчёт \"почему эта модель совершает именно эти ошибки\", вносить изменения в архитектуру **и проверять их экспериментально** - не надо слишком много теоретизировать.\n",
    "10. Ну и в целом **идти от простого к сложному**, за исключением случаев, когда точно по опыту знаешь, что простое не сработает. Когда есть мысль что-то добавить в архитектуру, спрашивать себя \"можно ли без этого\" или \"есть ли что-то более простое, что можно попробовать\".\n",
    "\n",
    "[Хороший сборник решений разных задач по NLP](https://github.com/microsoft/nlp-recipes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Семинар в директории `./stepik-dl-nlp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Теоретические вопросы: Свёрточные нейросети в обработке текста](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию, применяющую свёрточный модуль к последовательности. \n",
    "\n",
    "In the simplest case, the output value of the layer with input size $(N, C_{\\text{in}}, H, W)$ and output $(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})$ can be precisely described as:\n",
    "\n",
    "$$\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) + \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)$$\n",
    "\n",
    "where $\\star$ is the valid 2D cross-correlation operator (да короче свертка это), $N$ is a batch size, $C$ denotes a number of channels, $H$ is a height of input planes in pixels, and $W$ is width in pixels.\n",
    "\n",
    "**В проверялке numpy==1.14.1 (`np.lib.stride_tricks.sliding_window_view` отсутствует)**\n",
    "- используем фишку из [готового алгорима](https://towardsdatascience.com/fast-and-robust-sliding-window-vectorization-with-numpy-3ad950ed62f5), чтобы получать скользящее окно без цикла:\n",
    "  - в основе - свойства broadcasting (автоматическое расширение размерности) numpy\n",
    "  - строится хитрая матрица индексов для одного окна\n",
    "  - к ней добавляется размерность, из-за которой целевая матрица нужным образом расширяет свою размерность\n",
    "- остальное тривиально (не совсем)\n",
    "  - приведение тензоров к совместимому виду\n",
    "  - тензорное умножение (на самом деле тензорная редукция)\n",
    "  \n",
    "**Получилось просто красиво и исключительно быстро**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.536374007375313, 3.4055978271722807, 3.6420328514923983], [3.5379175544464094, 3.3156379278173618, 3.1978554753916804], [3.1155343252729804, 2.6461513962620473, 2.8292344624234116], [3.955826212094638, 2.6848769190617205, 2.355474927521796], [3.315456250217841, 2.5537928749371677, 2.979329283784809], [3.2335971417998324, 1.8896105910662777, 2.297264030641381], [2.5503637613247276, 2.441085171765234, 2.0663539814304355], [3.8006614791608166, 2.763727753920144, 3.030330546451793], [2.8770535772488457, 2.377839924681041, 2.6997168451820808], [3.4854598947993667, 1.9636904181843315, 1.9609925225671008], [3.3707917076650484, 2.6679105220798633, 2.2723789801177325], [4.179540206172763, 2.6157866984046363, 3.36235456621979]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "SAMPLES = \"\"\"[[0.6685863697825855, 0.9865099796400376], [0.32297881307708, 0.9908870158650515], [0.8359169063921157, 0.5443776713017927], [0.5363888029267118, 0.34755850459471804], [0.5966372342560426, 0.9834742307894673], [0.7371274295314912, 0.03279590013405109], [0.08580648148402137, 0.2850655085982621], [0.584942134340805, 0.7981720699451806], [0.19604496972304086, 0.991819073359733], [0.5622511488322055, 0.07928952553499002], [0.24152151330089744, 0.2865696384305756], [0.882594506643994, 0.5949729821472712], [0.10820233432771786, 0.8549971123651271], [0.18754460128195194, 0.6303661925298489], [0.3551051497971416, 0.9452980688158904], [0.6525044770663634, 0.8054232618991838]]\\n[[[0.8638059436915633, 0.4002290439648929, 0.8174398057982054, 0.34082478315585973, 0.5565832130592809], [0.08497737591188492, 0.7853885140384725, 0.1645895575029136, 0.6294907704137637, 0.8169862258229014]], [[0.21527072709338957, 0.9185427760457524, 0.5167378860756242, 0.12177789993763499, 0.4201289643444214], [0.8389450071463863, 0.6238637143288427, 0.5098771768082815, 0.1436853463091461, 0.12036561608743845]], [[0.8347050184618267, 0.12339875692133984, 0.13629086964943626, 0.623950910768403, 0.7092189295761365], [0.9578703072530402, 0.31612669923975534, 0.44018179806384916, 0.26615330385390035, 0.2745979551030847]]]\\n[0.6574440445518804, 0.3253787051567585, 0.3119672663686287]\"\"\", \n",
    "READER = (x for x in SAMPLES[0].split('\\n')); \n",
    "sys.stdin.readline = lambda: next(READER)       # тупо шоп не переписывать\n",
    "\n",
    "def parse_array(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def read_array():\n",
    "    return parse_array(sys.stdin.readline())\n",
    "\n",
    "def write_array(arr):\n",
    "    print(repr(arr.tolist()))\n",
    "\n",
    "def apply_convolution_trace(data, kernel, bias):\n",
    "    kernel_product = data @ kernel\n",
    "    res = [np.trace(kernel_product, pos, 2) for pos in range(data.shape[0] - kernel.shape[2] + 1)]\n",
    "\n",
    "    return res + bias\n",
    "\n",
    "def apply_convolution_looper(data, kernel, bias):\n",
    "    res = np.zeros([len(data)-kernel.shape[2]+1,len(kernel)])\n",
    "    for n in range(kernel.shape[0]):\n",
    "        for i in range(len(data)-kernel.shape[2]+1):\n",
    "            for j in range(kernel.shape[2]):\n",
    "                for c in range(kernel.shape[1]):\n",
    "                    res[i,n] += data[i+j, c] * kernel[n,c,j]\n",
    "            res[i,n] += bias[n]\n",
    "    return res\n",
    "\n",
    "def apply_convolution(data, kernel, bias):\n",
    "    \"\"\"\n",
    "    data - InLen x InChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns OutLen x OutChannels\n",
    "    \"\"\"\n",
    "    InLen = data.shape[0]                       \n",
    "    KernelSize = kernel.shape[2]        \n",
    "    Windows = InLen - KernelSize + 1\n",
    "\n",
    "    sliding_indexer = np.expand_dims(np.arange(KernelSize), 0) + \\\n",
    "                      np.expand_dims(np.arange(Windows), 0).T   # KernelSize x Windows\n",
    "    sliding_windows = data[sliding_indexer]                     # Windows x (KernelSize x InChannels)\n",
    "    # для тензора транспонирование, это обратный порядок измерений:         (KernelSize x InChannels) x OutChannels\n",
    "    return bias + np.tensordot(sliding_windows, kernel.T)       # -> Windows x OutChannels\n",
    "\n",
    "\n",
    "data = read_array()\n",
    "kernel = read_array()\n",
    "bias = read_array()\n",
    "\n",
    "result = apply_convolution(data, kernel, bias)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с форлупом:\n",
    "- на 3 порядка (!) быстрее форлупа\n",
    "- и даже немного (в 2 раза) быстрее матричного умножения\n",
    "- без ложной скромности, это лучшее решение на курсе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "inputs = (data, kernel, bias)\n",
    "\n",
    "# avoid caching\n",
    "rand_inputs = lambda : [np.random.random_sample([scale*s for s in arr.shape]) for arr in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 ms ± 740 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "apply_convolution(*rand_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.71 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "apply_convolution_trace(*rand_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.86 s ± 17.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "apply_convolution_looper(*rand_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = rand_inputs()\n",
    "np.allclose(apply_convolution(*arr), apply_convolution_trace(*arr), apply_convolution_looper(*arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы применяете свёрточный модуль к данным: \n",
    "$$y = convolve(x, kernel, bias)$$ \n",
    "\n",
    "где \n",
    " \n",
    "$x \\in \\mathbb{R}^{InLen \\times InChannels}$ - входная последовательность,  \n",
    "$kernel \\in \\mathbb{R}^{OutChannels \\times InChannels \\times KernelSize}$ - ядро свёртки,  \n",
    "$bias \\in \\mathbb{R}^{OutChannels}$ - параметры сдвига для каждого выходного канала.\n",
    "\n",
    "Напишите функцию, которая находит значение производной результата по ядру свёртки: $\\frac{\\partial y} {\\partial kernel}$\n",
    "\n",
    "Интуитивно как то так:\n",
    "- градиент это сумма тех входных данных, которые аккумулируются на соответствующих компонентах ядра\n",
    "- это происходит в виде скользящего окна, поэтому вот оно\n",
    "- по измерению OutLen (количество окон, т.е. первое измерение) окна схлопываются\n",
    "- информация о выходных каналах исключительно в ядре, поэтому производные по разным каналам будут равны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.4301533243865463, 3.253085788359958, 3.3909318100218258], [1.8928047647857822, 1.6931753947579833, 1.6786220604803275], [2.643020708074734, 2.8967149590920043, 3.491658593272137]], [[2.4301533243865463, 3.253085788359958, 3.3909318100218258], [1.8928047647857822, 1.6931753947579833, 1.6786220604803275], [2.643020708074734, 2.8967149590920043, 3.491658593272137]]]\n"
     ]
    }
   ],
   "source": [
    "SAMPLES = \"\"\"[[0.1559846921787793, 0.31890243279158936, 0.4294841981370352], [0.6287087193276831, 0.041166388481120975, 0.0670771539905104], [0.15852860049868056, 0.5535509628878403, 0.7578893631796608], [0.505354018460584, 0.39104507392557886, 0.267830936523598], [0.35352084058390487, 0.09557605719492113, 0.17762289879326898], [0.17895124947325458, 0.2038143268404633, 0.45431038892117714], [0.44910520386366004, 0.28874952266426823, 0.48880576852948343], [0.978917156152191, 0.11927306276379035, 0.6831784491543058], [0.7665547409895508, 0.02661305420346527, 0.662020788170643]]\\n[[0.9423069699375323, 2.235723993887441], [1.051430354504024, 2.5441990558270864], [1.3060781439427196, 2.77617352972661], [1.1097986223660692, 2.019161891632857], [0.8312656308401454, 2.1968468090151005], [1.0883546513743934, 3.182136137325698], [1.4545203460970286, 3.3294233853738975]]\\n[[[0.7285150274194675, 0.13990616439149894, 0.08385531710791316], [0.8119118106104425, 0.19272155988045991, 0.010762309371285528], [0.5242309485683324, 0.33106798748722055, 0.2219888201243384]], [[0.31261137319823096, 0.3951341806652614, 0.954412244770657], [0.5475239344122861, 0.6407966544293683, 0.2840031545245296], [0.9267337670407934, 0.626334029479077, 0.4315268897320006]]]\\n[0.03900532471824536, 0.6619593919342232]\"\"\", \n",
    "READER = (x for x in SAMPLES[0].split('\\n')); \n",
    "sys.stdin.readline = lambda: next(READER)       # тупо шоп не переписывать\n",
    "\n",
    "\n",
    "def calculate_kernel_grad(x, y, kernel, bias):\n",
    "    \"\"\"\n",
    "    x - InLen x InChannels\n",
    "    y - OutLen x OutChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns OutChannels x InChannels x KernelSize\n",
    "    \"\"\"\n",
    "    InLen = x.shape[0]               \n",
    "    KernelSize = kernel.shape[2]        \n",
    "    OutLen = InLen - KernelSize + 1\n",
    "\n",
    "    sliding_indexer = np.expand_dims(np.arange(KernelSize), 0) + \\\n",
    "                      np.expand_dims(np.arange(OutLen), 0).T   # KernelSize x OutLen\n",
    "    x_sliding = x[sliding_indexer]                             # OutLen x KernelSize x InChannels\n",
    "\n",
    "    return np.sum(x_sliding, axis=0).T + np.zeros_like(kernel) # неявный бродкаст к нужной размерности\n",
    "\n",
    "\n",
    "x = read_array()\n",
    "y = read_array()\n",
    "kernel = read_array()\n",
    "bias = read_array()\n",
    "\n",
    "result = calculate_kernel_grad(x, y, kernel, bias)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы применяете свёрточный модуль к данным: \n",
    "\n",
    "$$y = convolve(x, kernel, bias)$$ \n",
    "\n",
    "\n",
    "где \n",
    "\n",
    "$x \\in \\mathbb{R}^{InLen \\times InChannels}$ - входная последовательность,   \n",
    "$kernel \\in \\mathbb{R}^{OutChannels \\times InChannels \\times KernelSize}$ - ядро свёртки,  \n",
    "$bias \\in \\mathbb{R}^{OutChannels}$ - параметры сдвига для каждого выходного канала.\n",
    "\n",
    "Напишите функцию, которая находит значение производной результата по входу: $\\frac{\\partial y} {\\partial x}$\n",
    "\n",
    "- задача, собрать компоненты ядра, с которыми перемножается каждый вход\n",
    "- на чистом numpy не получилось (ПОЛУЧИЛОСЬ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3758750809861735, 1.7854909022976875], [3.0778457550346365, 3.305123370918622], [4.022592414095037, 5.4085957902356965], [4.022592414095037, 5.4085957902356965], [4.022592414095037, 5.4085957902356965], [4.022592414095037, 5.4085957902356965], [2.646717333108864, 3.623104887938009], [0.9447466590604012, 2.1034724193170744]]\n"
     ]
    }
   ],
   "source": [
    "SAMPLES = \"\"\"[[0.5031766517322117, 0.30744410216949514], [0.04690208449415345, 0.322727131626243], [0.1388690574185909, 0.48576543724022325], [0.5260018011862109, 0.5859221562109312], [0.9194272143904142, 0.3887293155713266], [0.26873714217871125, 0.9546207791313607], [0.8974007607375208, 0.5713329992292489], [0.378989716528242, 0.49787928388753266]]\\n[[1.5157583762374225, 0.9460413662192456, 0.9802340338281511], [1.5728362445918327, 0.996409724139607, 1.2530013664472253], [1.9068174476481374, 1.430592927945995, 1.6704630594015581], [2.189768979209843, 2.3149543871163503, 2.1601629609824995], [2.8353457102707083, 1.7422359297539565, 1.816707087141475], [2.0532913525958474, 1.9924093441385802, 2.3069493556139014]]\\n[[[0.8077620147648772, 0.006392942850116379, 0.6080212915877307], [0.6288229869798402, 0.6410664904844843, 0.75419330562945]], [[0.5355186530459589, 0.9211024178840701, 0.27725553497982014], [0.4507098181629161, 0.081570594016668, 0.8234980185346139]], [[0.0325944131753374, 0.7744753133142763, 0.05946983249285043], [0.7059580971549311, 0.7969953841197822, 0.5257810951530107]]]\\n[0.2579976950685653, 0.029957050945287222, 0.18958928880952108]\"\"\", \n",
    "READER = (x for x in SAMPLES[0].split('\\n')); \n",
    "sys.stdin.readline = lambda: next(READER)       # тупо шоп не переписывать\n",
    "\n",
    "def calculate_conv_x_grad_looper(x, y, kernel, bias):\n",
    "    in_len = len(x)\n",
    "    in_channels = len(x[0])\n",
    "    out_ch = len(bias)\n",
    "    kernel_size = len(kernel[0][0])\n",
    "    output_len = in_len - kernel_size + 1\n",
    "\n",
    "    result=np.zeros(x.shape)\n",
    "\n",
    "    for pos in range(output_len):\n",
    "        for oc in range(out_ch):\n",
    "            for k in range(kernel_size):\n",
    "                for ic in range(in_channels):\n",
    "                    result[pos + k][ic] += kernel[oc][ic][k]\n",
    "\n",
    "    return result\n",
    "\n",
    "def all_traces_2d(arr, flip=False):\n",
    "    \"\"\" на основе стаковерфлоу:\n",
    "    - лучшее решение для вычисления всех следов матрицы\n",
    "    \"\"\"\n",
    "    assert arr.ndim == 2\n",
    "    if flip: arr = np.fliplr(arr)\n",
    "    indexes = np.indices(arr.shape).sum(axis=0).flat\n",
    "    return np.bincount(indexes, weights=arr.flat)\n",
    "\n",
    "def calculate_conv_x_grad(x, y, kernel, bias):\n",
    "    \"\"\"\n",
    "    x - InLen x InChannels\n",
    "    y - OutLen x OutChannels\n",
    "    kernel - OutChannels x InChannels x KernelSize\n",
    "    bias - OutChannels\n",
    "\n",
    "    returns InLen x InChannels\n",
    "    \"\"\"\n",
    "    InLen = x.shape[0]               \n",
    "    KernelSize = kernel.shape[2]        \n",
    "    OutLen = InLen - KernelSize + 1\n",
    "    sliding_indexer = np.expand_dims(np.arange(KernelSize), 0) + \\\n",
    "                      np.expand_dims(np.arange(OutLen), 0).T   # KernelSize x OutLen\n",
    "    kernel_expander = np.zeros_like(x[sliding_indexer])\n",
    "    kernel_expand = np.rollaxis(kernel, -1) + np.expand_dims(kernel_expander, 1) \n",
    "    kernel_sums = kernel_expand.sum(axis=2)\n",
    "    \n",
    "    return np.vectorize(all_traces_2d, signature=\"(i,j)->(k)\")(np.rollaxis(kernel_sums, -1)).T\n",
    "\n",
    "x = read_array()\n",
    "y = read_array()\n",
    "kernel = read_array()\n",
    "bias = read_array()\n",
    "\n",
    "result = calculate_conv_x_grad(x, y, kernel, bias)\n",
    "\n",
    "write_array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним форлуп и нампай:\n",
    "- на чистейшем numpy получилось на 2 порядка быстрее (в 100 раз)\n",
    "- Боже, как я хорош, срочно в продакшен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "inputs = (x, y, kernel, bias)\n",
    "\n",
    "# avoid caching\n",
    "rand_inputs = lambda : [np.random.random_sample([scale*s for s in arr.shape]) for arr in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.01 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calculate_conv_x_grad(*rand_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calculate_conv_x_grad_looper(*rand_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = rand_inputs()\n",
    "np.allclose(calculate_conv_x_grad(*arr), calculate_conv_x_grad_looper(*arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы разрабатываете нейросеть, состоящую из последовательности свёрточных слоёв с разными параметрами:\n",
    "\n",
    "$kernel >= 1, kernel \\% 2 == 1$ - размер ядра свёртки (обязательно нечётный)  \n",
    "$dilation >= 1$ - коэффициент прореживания или расстояние между позициями элементов, учитываемых одной свёрткой (если dilation = 1, то это \"плотная\" свёртка, если dilation = 2, пропускается каждый второй элемент)  \n",
    "\n",
    "Напишите функцию для расчёта ширины рецептивного поля - наибольшего расстояния между элементами входной последовательности (+1), которые влияют на один и тот же элемент выходной последовательности.\n",
    "\n",
    "Получается типа:\n",
    "$$r_{out} = r_{in} + (k−1) \\cdot d$$\n",
    "\n",
    "где\n",
    "\n",
    "$r_{in}$ - ширина рецептивного поля текущего слоя  \n",
    "$r_{out}$ - ширина рецептивного поля последующего слоя  \n",
    "$d$ - коэффициент прореживания  \n",
    "$k$ - размер ядра свёртки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "SAMPLES = \"\"\"[9, 9, 3]\\n[2, 3, 4]\"\"\", \n",
    "READER = (x for x in SAMPLES[0].split('\\n')); \n",
    "sys.stdin.readline = lambda: next(READER)       # тупо шоп не переписывать\n",
    "\n",
    "import collections\n",
    "\n",
    "LayerInfo = collections.namedtuple('LayerInfo', ('kernel_size', 'dilation'))\n",
    "\n",
    "def calculate_receptive_field(layers):\n",
    "    \"\"\"\n",
    "    layers - list of LayerInfo\n",
    "\n",
    "    returns int - receptive field size\n",
    "    \"\"\"\n",
    "    receptive_field = 1\n",
    "    for l in layers:\n",
    "        receptive_field += (l.kernel_size - 1) * l.dilation\n",
    "\n",
    "    return receptive_field\n",
    "\n",
    "    \n",
    "kernels = read_array()\n",
    "dilations = read_array()\n",
    "\n",
    "layers = [LayerInfo(k, d) for k, d in zip(kernels, dilations)]\n",
    "\n",
    "result = calculate_receptive_field(layers)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75291dc0307ea48294888123147845d2e15abd18d38848ca6ac05a6fe8c88425"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
